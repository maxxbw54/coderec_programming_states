{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "import sklearn\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from pyhhmm.gaussian import GaussianHMM\n",
    "from pyhhmm.multinomial import MultinomialHMM\n",
    "from pyhhmm.heterogeneous import HeterogeneousHMM\n",
    "import pyhhmm.utils as hu\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_path = r'../data/logs_7-13_hussein.csv'\n",
    "restricted_logs_path = r'../data/restricted_7-13_hussein.csv'\n",
    "extented_model_path = r'../data/generated_data/extended_states_7-13.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimeGenerated</th>\n",
       "      <th>TrackingId</th>\n",
       "      <th>CompletionId</th>\n",
       "      <th>Name</th>\n",
       "      <th>PropertiesJson</th>\n",
       "      <th>MeasurementsJson</th>\n",
       "      <th>SessionId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>newSession</th>\n",
       "      <th>SessionID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-06-06T21:28:25.007Z</td>\n",
       "      <td>d41177694f19740b031bca875fe75c35</td>\n",
       "      <td>cmpl-5GEYpSBgkSgGU5U1KS8R14KDrKUpG</td>\n",
       "      <td>copilot/ghostText.shown</td>\n",
       "      <td>{'VSCode.ABExp.Features': 'livesharecontinuous...</td>\n",
       "      <td>{'compCharLen': 218.0, 'confidence': 0.6814250...</td>\n",
       "      <td>f89b2779-df37-46e7-a71e-6c28968064ea1654550891557</td>\n",
       "      <td>078a6302949265084294652f07e8300f77b3dfa6784901...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-06-06T21:28:28.391Z</td>\n",
       "      <td>d41177694f19740b031bca875fe75c35</td>\n",
       "      <td>cmpl-5GEYpSBgkSgGU5U1KS8R14KDrKUpG</td>\n",
       "      <td>copilot/ghostText.accepted</td>\n",
       "      <td>{'VSCode.ABExp.Features': 'livesharecontinuous...</td>\n",
       "      <td>{'compCharLen': 227.0, 'confidence': 0.6814250...</td>\n",
       "      <td>f89b2779-df37-46e7-a71e-6c28968064ea1654550891557</td>\n",
       "      <td>078a6302949265084294652f07e8300f77b3dfa6784901...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-06-06T21:28:32.617Z</td>\n",
       "      <td>d41177694f19740b031bca875fe75c35</td>\n",
       "      <td>cmpl-5GEYxVR6f21oGQK3JlcMxmAsxvZ9m</td>\n",
       "      <td>copilot/ghostText.shown</td>\n",
       "      <td>{'VSCode.ABExp.Features': 'livesharecontinuous...</td>\n",
       "      <td>{'compCharLen': 59.0, 'confidence': 0.82290775...</td>\n",
       "      <td>f89b2779-df37-46e7-a71e-6c28968064ea1654550891557</td>\n",
       "      <td>078a6302949265084294652f07e8300f77b3dfa6784901...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-06-06T21:28:34.047Z</td>\n",
       "      <td>d41177694f19740b031bca875fe75c35</td>\n",
       "      <td>cmpl-5GEYxVR6f21oGQK3JlcMxmAsxvZ9m</td>\n",
       "      <td>copilot/ghostText.rejected</td>\n",
       "      <td>{'VSCode.ABExp.Features': 'livesharecontinuous...</td>\n",
       "      <td>{'compCharLen': 59.0, 'confidence': 0.82290775...</td>\n",
       "      <td>f89b2779-df37-46e7-a71e-6c28968064ea1654550891557</td>\n",
       "      <td>078a6302949265084294652f07e8300f77b3dfa6784901...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-06-06T21:28:34.05Z</td>\n",
       "      <td>d41177694f19740b031bca875fe75c35</td>\n",
       "      <td>cmpl-5GEYzV048YVHP9214bqg9lgOUn4uw</td>\n",
       "      <td>copilot/ghostText.shown</td>\n",
       "      <td>{'VSCode.ABExp.Features': 'livesharecontinuous...</td>\n",
       "      <td>{'compCharLen': 42.0, 'confidence': 0.87763204...</td>\n",
       "      <td>f89b2779-df37-46e7-a71e-6c28968064ea1654550891557</td>\n",
       "      <td>078a6302949265084294652f07e8300f77b3dfa6784901...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              TimeGenerated                        TrackingId  \\\n",
       "0  2022-06-06T21:28:25.007Z  d41177694f19740b031bca875fe75c35   \n",
       "1  2022-06-06T21:28:28.391Z  d41177694f19740b031bca875fe75c35   \n",
       "2  2022-06-06T21:28:32.617Z  d41177694f19740b031bca875fe75c35   \n",
       "3  2022-06-06T21:28:34.047Z  d41177694f19740b031bca875fe75c35   \n",
       "4   2022-06-06T21:28:34.05Z  d41177694f19740b031bca875fe75c35   \n",
       "\n",
       "                         CompletionId                        Name  \\\n",
       "0  cmpl-5GEYpSBgkSgGU5U1KS8R14KDrKUpG     copilot/ghostText.shown   \n",
       "1  cmpl-5GEYpSBgkSgGU5U1KS8R14KDrKUpG  copilot/ghostText.accepted   \n",
       "2  cmpl-5GEYxVR6f21oGQK3JlcMxmAsxvZ9m     copilot/ghostText.shown   \n",
       "3  cmpl-5GEYxVR6f21oGQK3JlcMxmAsxvZ9m  copilot/ghostText.rejected   \n",
       "4  cmpl-5GEYzV048YVHP9214bqg9lgOUn4uw     copilot/ghostText.shown   \n",
       "\n",
       "                                      PropertiesJson  \\\n",
       "0  {'VSCode.ABExp.Features': 'livesharecontinuous...   \n",
       "1  {'VSCode.ABExp.Features': 'livesharecontinuous...   \n",
       "2  {'VSCode.ABExp.Features': 'livesharecontinuous...   \n",
       "3  {'VSCode.ABExp.Features': 'livesharecontinuous...   \n",
       "4  {'VSCode.ABExp.Features': 'livesharecontinuous...   \n",
       "\n",
       "                                    MeasurementsJson  \\\n",
       "0  {'compCharLen': 218.0, 'confidence': 0.6814250...   \n",
       "1  {'compCharLen': 227.0, 'confidence': 0.6814250...   \n",
       "2  {'compCharLen': 59.0, 'confidence': 0.82290775...   \n",
       "3  {'compCharLen': 59.0, 'confidence': 0.82290775...   \n",
       "4  {'compCharLen': 42.0, 'confidence': 0.87763204...   \n",
       "\n",
       "                                           SessionId  \\\n",
       "0  f89b2779-df37-46e7-a71e-6c28968064ea1654550891557   \n",
       "1  f89b2779-df37-46e7-a71e-6c28968064ea1654550891557   \n",
       "2  f89b2779-df37-46e7-a71e-6c28968064ea1654550891557   \n",
       "3  f89b2779-df37-46e7-a71e-6c28968064ea1654550891557   \n",
       "4  f89b2779-df37-46e7-a71e-6c28968064ea1654550891557   \n",
       "\n",
       "                                              UserId  newSession  SessionID  \n",
       "0  078a6302949265084294652f07e8300f77b3dfa6784901...           1          0  \n",
       "1  078a6302949265084294652f07e8300f77b3dfa6784901...           0          0  \n",
       "2  078a6302949265084294652f07e8300f77b3dfa6784901...           0          0  \n",
       "3  078a6302949265084294652f07e8300f77b3dfa6784901...           0          0  \n",
       "4  078a6302949265084294652f07e8300f77b3dfa6784901...           0          0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_logs = pd.read_csv (logs_path)\n",
    "# convert json into dict\n",
    "df_logs.PropertiesJson = [json.loads(df_logs.PropertiesJson[i]) for i in range(len(df_logs.PropertiesJson))]\n",
    "df_logs.MeasurementsJson = [json.loads(df_logs.MeasurementsJson[i]) for i in range(len(df_logs.MeasurementsJson))]\n",
    "# mark new sessions based on timestamp difference of more than 30 minutes\n",
    "timestamps = df_logs.TimeGenerated.to_numpy()\n",
    "timestamps_datetime = [pd.to_datetime(timestamps[i]) for i in range(len(timestamps))]\n",
    "#  difference between timestamps\n",
    "timestamps_diff = [timestamps_datetime[i+1] - timestamps_datetime[i] for i in range(len(timestamps_datetime)-1)]\n",
    "#  convert to minutes\n",
    "timestamps_diff_min = [timestamps_diff[i].total_seconds()/60 for i in range(len(timestamps_diff))]\n",
    "# check if consecutive differences are bigger than 30 minutes \n",
    "timestamps_diff_min_consecutive = [1] + [1 if timestamps_diff_min[i-1] > 30 else 0 for i in range(1,len(timestamps_diff_min)+1)] \n",
    "# create array where if timestamps_diff_min_consecutive is 1 you add 1 to the previous value\n",
    "new_session_counter = [0] * len(timestamps_diff_min_consecutive)\n",
    "for i in range(1, len(timestamps_diff_min_consecutive)):\n",
    "    new_session_counter[i] = new_session_counter[i-1] + timestamps_diff_min_consecutive[i]\n",
    "\n",
    "\n",
    "df_logs['newSession'] = timestamps_diff_min_consecutive\n",
    "df_logs['SessionID'] = new_session_counter\n",
    "df_logs.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimeGenerated</th>\n",
       "      <th>TrackingId</th>\n",
       "      <th>CompletionId</th>\n",
       "      <th>Name</th>\n",
       "      <th>PropertiesJson</th>\n",
       "      <th>MeasurementsJson</th>\n",
       "      <th>SessionId</th>\n",
       "      <th>UserId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-06-06T21:28:24.278Z</td>\n",
       "      <td>d41177694f19740b031bca875fe75c35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>copilot/engine.prompt</td>\n",
       "      <td>{'VSCode.ABExp.Features': 'livesharecontinuous...</td>\n",
       "      <td>{'promptCharLen': 52.0, 'timeSinceIssuedMs': 2...</td>\n",
       "      <td>f89b2779-df37-46e7-a71e-6c28968064ea1654550891557</td>\n",
       "      <td>078a6302949265084294652f07e8300f77b3dfa6784901...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-06-06T21:28:25Z</td>\n",
       "      <td>d41177694f19740b031bca875fe75c35</td>\n",
       "      <td>cmpl-5GEYpSBgkSgGU5U1KS8R14KDrKUpG</td>\n",
       "      <td>copilot/engine.completion</td>\n",
       "      <td>{'VSCode.ABExp.Features': 'livesharecontinuous...</td>\n",
       "      <td>{'timeSinceIssuedMs': 2.0}</td>\n",
       "      <td>f89b2779-df37-46e7-a71e-6c28968064ea1654550891557</td>\n",
       "      <td>078a6302949265084294652f07e8300f77b3dfa6784901...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-06-06T21:28:25.003Z</td>\n",
       "      <td>d41177694f19740b031bca875fe75c35</td>\n",
       "      <td>cmpl-5GEYpSBgkSgGU5U1KS8R14KDrKUpG</td>\n",
       "      <td>copilot/engine.completion</td>\n",
       "      <td>{'VSCode.ABExp.Features': 'livesharecontinuous...</td>\n",
       "      <td>{'timeSinceIssuedMs': 1.0}</td>\n",
       "      <td>f89b2779-df37-46e7-a71e-6c28968064ea1654550891557</td>\n",
       "      <td>078a6302949265084294652f07e8300f77b3dfa6784901...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-06-06T21:28:25.004Z</td>\n",
       "      <td>d41177694f19740b031bca875fe75c35</td>\n",
       "      <td>cmpl-5GEYpSBgkSgGU5U1KS8R14KDrKUpG</td>\n",
       "      <td>copilot/engine.completion</td>\n",
       "      <td>{'VSCode.ABExp.Features': 'livesharecontinuous...</td>\n",
       "      <td>{'timeSinceIssuedMs': 0.0}</td>\n",
       "      <td>f89b2779-df37-46e7-a71e-6c28968064ea1654550891557</td>\n",
       "      <td>078a6302949265084294652f07e8300f77b3dfa6784901...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-06-06T21:28:28.785Z</td>\n",
       "      <td>d41177694f19740b031bca875fe75c35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>copilot/engine.prompt</td>\n",
       "      <td>{'VSCode.ABExp.Features': 'livesharecontinuous...</td>\n",
       "      <td>{'promptCharLen': 270.0, 'timeSinceIssuedMs': ...</td>\n",
       "      <td>f89b2779-df37-46e7-a71e-6c28968064ea1654550891557</td>\n",
       "      <td>078a6302949265084294652f07e8300f77b3dfa6784901...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              TimeGenerated                        TrackingId  \\\n",
       "0  2022-06-06T21:28:24.278Z  d41177694f19740b031bca875fe75c35   \n",
       "1      2022-06-06T21:28:25Z  d41177694f19740b031bca875fe75c35   \n",
       "2  2022-06-06T21:28:25.003Z  d41177694f19740b031bca875fe75c35   \n",
       "3  2022-06-06T21:28:25.004Z  d41177694f19740b031bca875fe75c35   \n",
       "4  2022-06-06T21:28:28.785Z  d41177694f19740b031bca875fe75c35   \n",
       "\n",
       "                         CompletionId                       Name  \\\n",
       "0                                 NaN      copilot/engine.prompt   \n",
       "1  cmpl-5GEYpSBgkSgGU5U1KS8R14KDrKUpG  copilot/engine.completion   \n",
       "2  cmpl-5GEYpSBgkSgGU5U1KS8R14KDrKUpG  copilot/engine.completion   \n",
       "3  cmpl-5GEYpSBgkSgGU5U1KS8R14KDrKUpG  copilot/engine.completion   \n",
       "4                                 NaN      copilot/engine.prompt   \n",
       "\n",
       "                                      PropertiesJson  \\\n",
       "0  {'VSCode.ABExp.Features': 'livesharecontinuous...   \n",
       "1  {'VSCode.ABExp.Features': 'livesharecontinuous...   \n",
       "2  {'VSCode.ABExp.Features': 'livesharecontinuous...   \n",
       "3  {'VSCode.ABExp.Features': 'livesharecontinuous...   \n",
       "4  {'VSCode.ABExp.Features': 'livesharecontinuous...   \n",
       "\n",
       "                                    MeasurementsJson  \\\n",
       "0  {'promptCharLen': 52.0, 'timeSinceIssuedMs': 2...   \n",
       "1                         {'timeSinceIssuedMs': 2.0}   \n",
       "2                         {'timeSinceIssuedMs': 1.0}   \n",
       "3                         {'timeSinceIssuedMs': 0.0}   \n",
       "4  {'promptCharLen': 270.0, 'timeSinceIssuedMs': ...   \n",
       "\n",
       "                                           SessionId  \\\n",
       "0  f89b2779-df37-46e7-a71e-6c28968064ea1654550891557   \n",
       "1  f89b2779-df37-46e7-a71e-6c28968064ea1654550891557   \n",
       "2  f89b2779-df37-46e7-a71e-6c28968064ea1654550891557   \n",
       "3  f89b2779-df37-46e7-a71e-6c28968064ea1654550891557   \n",
       "4  f89b2779-df37-46e7-a71e-6c28968064ea1654550891557   \n",
       "\n",
       "                                              UserId  \n",
       "0  078a6302949265084294652f07e8300f77b3dfa6784901...  \n",
       "1  078a6302949265084294652f07e8300f77b3dfa6784901...  \n",
       "2  078a6302949265084294652f07e8300f77b3dfa6784901...  \n",
       "3  078a6302949265084294652f07e8300f77b3dfa6784901...  \n",
       "4  078a6302949265084294652f07e8300f77b3dfa6784901...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_logs_restr = pd.read_csv(restricted_logs_path)\n",
    "df_logs_restr.PropertiesJson = [json.loads(df_logs_restr.PropertiesJson[i]) for i in range(len(df_logs_restr.PropertiesJson))]\n",
    "df_logs_restr.MeasurementsJson = [json.loads(df_logs_restr.MeasurementsJson[i]) for i in range(len(df_logs_restr.MeasurementsJson))]\n",
    "df_logs_restr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Observable State  Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dag {\n",
    "bb=\"0,0,1,1\"\n",
    "\"Browse Suggestions\" [pos=\"0.840,0.616\"]\n",
    "\"Editing Suggestion\" [latent,pos=\"0.177,0.099\"]\n",
    "\"Ghost Text Appears\" [pos=\"0.656,0.176\"]\n",
    "\"User Accepts Ghost Text\" [outcome,pos=\"0.491,0.684\"]\n",
    "\"User Before Action\" [pos=\"0.644,0.393\"]\n",
    "\"User Rejects Ghost Text\" [outcome,pos=\"0.669,0.705\"]\n",
    "\"User Typing/Paused\" [pos=\"0.183,0.501\"]\n",
    "\"Writing New Code\" [latent,pos=\"0.326,0.194\"]\n",
    "Paused [pos=\"0.289,0.323\"]\n",
    "Typing [pos=\"0.131,0.309\"]\n",
    "\"Browse Suggestions\" -> \"Ghost Text Appears\"\n",
    "\"Editing Suggestion\" -> \"Ghost Text Appears\"\n",
    "\"Ghost Text Appears\" -> \"User Before Action\"\n",
    "\"User Accepts Ghost Text\" -> \"User Typing/Paused\"\n",
    "\"User Before Action\" -> \"Browse Suggestions\"\n",
    "\"User Before Action\" -> \"User Accepts Ghost Text\"\n",
    "\"User Before Action\" -> \"User Rejects Ghost Text\"\n",
    "\"User Rejects Ghost Text\" -> \"User Typing/Paused\"\n",
    "\"User Typing/Paused\" -> Paused\n",
    "\"User Typing/Paused\" -> Typing\n",
    "\"Writing New Code\" -> \"Ghost Text Appears\"\n",
    "Paused -> \"Ghost Text Appears\"\n",
    "Typing -> \"Editing Suggestion\"\n",
    "Typing -> \"Writing New Code\"\n",
    "}\n",
    "](images/state_diagram_1.png)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:25<00:00,  2.52it/s]\n",
      "100%|██████████| 63/63 [01:08<00:00,  1.08s/it]\n"
     ]
    }
   ],
   "source": [
    "# create observable state diagram\n",
    "column_names = [\"TimeGenerated\", \"CompletionId\", \"UserId\", \"SessionId\",\"StateName\", \"HiddenState\",\"TimeSpentInState\",\"CurrentSuggestion\", \"CurrentPrompt\", \"Measurements\"]\n",
    "unique_session_ids = np.unique(df_logs.SessionID) # or SessionId  \n",
    "df_observations_states = []\n",
    "import copy\n",
    "for id_unique in tqdm(unique_session_ids):\n",
    "    # split on SessionID\n",
    "    df_task = df_logs[df_logs.SessionID == id_unique]\n",
    "    df_names = df_task.Name.to_numpy()\n",
    "    df_states = pd.DataFrame(columns= column_names)\n",
    "    in_Shown = False\n",
    "    last_completion_id = 0 \n",
    "    # iterate through data frame\n",
    "    last_timestamp = -1\n",
    "    for index, row in df_task.iterrows():\n",
    "        # ignore stillInCodes for now\n",
    "        name = row['Name']\n",
    "        completion_id = row['CompletionId']\n",
    "        if name == 'copilot/ghostText.stillInCode':\n",
    "            continue\n",
    "        choiceIndex = row.PropertiesJson['choiceIndex']\n",
    "        df_logs_restr_completion = df_logs_restr[df_logs_restr.CompletionId == completion_id]\n",
    "        completion = \"\"\n",
    "        prompt = \"\"\n",
    "        # iterate through restricted data frame to get prompt and completion\n",
    "        for index_restr, row_restr in df_logs_restr_completion.iterrows():\n",
    "            if 'completionTextJson' in row_restr.PropertiesJson and 'choiceIndex' in row_restr.PropertiesJson:\n",
    "                if row_restr.PropertiesJson['choiceIndex'] == choiceIndex:\n",
    "                    completion = row_restr.PropertiesJson['completionTextJson']\n",
    "            if 'hypotheticalPromptJson' in row_restr.PropertiesJson:\n",
    "                prompt = row_restr.PropertiesJson['hypotheticalPromptJson']\n",
    "\n",
    "        # find prompt in completion \n",
    "        index_restr = df_logs_restr_completion.index[0]\n",
    "        df_prompt_compl = df_logs_restr.loc[index_restr-1]\n",
    "        if 'promptJson' in df_prompt_compl.PropertiesJson:\n",
    "            prompt = df_prompt_compl.PropertiesJson['promptJson']\n",
    "\n",
    "        user_id = row['UserId']\n",
    "        session_id = row['SessionId']\n",
    "\n",
    "\n",
    "        if last_timestamp != -1:\n",
    "            # difference\n",
    "            time_difference =  pd.to_datetime(row['TimeGenerated']) - pd.to_datetime(last_timestamp) \n",
    "            time_difference_sec = time_difference.total_seconds()\n",
    "        else:\n",
    "            last_timestamp = row['TimeGenerated']\n",
    "            time_difference_sec = 0 \n",
    "        \n",
    "\n",
    "        state_dict = {  'TimeGenerated': row['TimeGenerated'],\n",
    "                        'CompletionId': completion_id,\n",
    "                        'UserId': user_id,\n",
    "                        'SessionId': session_id,\n",
    "                        'StateName': \"TBD\",\n",
    "                        'HiddenState': \"TBD\",\n",
    "                        'TimeSpentInState': time_difference_sec,\n",
    "                        'CurrentSuggestion': completion,\n",
    "                        'CurrentPrompt': prompt,\n",
    "                        'Measurements': [row['MeasurementsJson']]} # might add more properties later\n",
    "        \n",
    "        # just keep track if in shown state\n",
    "        if name != 'copilot/ghostText.shown' and name != 'copilot/ghostText.shownFromCache':\n",
    "            in_Shown = False\n",
    "            last_completion_id = completion_id\n",
    "\n",
    "        # all states tracking\n",
    "        if name == 'copilot/ghostText.shown' or name == 'copilot/ghostText.shownFromCache':\n",
    "            # if previous state was also shown\n",
    "            if in_Shown:\n",
    "                # if we are in shown and the completion id is the same as the last one, user is browsing suggestions\n",
    "                if last_completion_id == completion_id:\n",
    "                    new_state = copy.deepcopy(state_dict)\n",
    "                    new_state['StateName'] = 'Browsing'\n",
    "                    new_state['HiddenState'] = 'UserBeforeAction'\n",
    "\n",
    "                    df_states = pd.concat([df_states, pd.DataFrame(new_state)])\n",
    "\n",
    "                # if we were previously in shown, and now we have a new shown, then we previously rejected the shown\n",
    "                # typed, and then got another suggestion\n",
    "                else:\n",
    "                    new_state = copy.deepcopy(state_dict)\n",
    "                    new_state['StateName'] = 'Shown' # hidden rejected\n",
    "                    new_state['HiddenState'] = 'UserTypingOrPaused'\n",
    "\n",
    "                    df_states = pd.concat([df_states, pd.DataFrame(new_state)])\n",
    "            else:\n",
    "                # if previous was not shown, then user was typing/paused\n",
    "                new_state = copy.deepcopy(state_dict)\n",
    "                new_state['StateName'] = 'Shown'\n",
    "                new_state['HiddenState'] = 'UserTypingOrPaused'\n",
    "                \n",
    "                df_states = pd.concat([df_states, pd.DataFrame(new_state)])          \n",
    "            last_completion_id = completion_id\n",
    "            in_Shown = True\n",
    "\n",
    "        elif name == 'copilot/ghostText.accepted':\n",
    "            # before accepting, user was thinking\n",
    "            new_state = copy.deepcopy(state_dict)\n",
    "            new_state['StateName'] = 'Accepted'\n",
    "            new_state['HiddenState'] = 'UserBeforeAction'\n",
    "            df_states = pd.concat([df_states, pd.DataFrame(new_state)])\n",
    "        elif name == 'copilot/ghostText.rejected':\n",
    "            new_state = copy.deepcopy(state_dict)\n",
    "            new_state['StateName'] = 'Rejected'\n",
    "            new_state['HiddenState'] = 'UserBeforeAction'\n",
    "            df_states = pd.concat([df_states, pd.DataFrame(new_state)])\n",
    "        last_timestamp = row['TimeGenerated']\n",
    "\n",
    "    df_observations_states.append(df_states)\n",
    "    \n",
    "# decipher paused vs typing\n",
    "for session_id in range(len(df_observations_states)):\n",
    "    # iterate through dataframe and modify statename\n",
    "    for index in range(1, len(df_observations_states[session_id])):\n",
    "        if df_observations_states[session_id].iloc[index]['StateName'] == 'Shown':\n",
    "            if df_observations_states[session_id].iloc[index-1]['StateName'] == 'Accepted':\n",
    "                code_lenght = df_observations_states[session_id].iloc[index]['Measurements']['documentLength']\n",
    "                index2 = index -1\n",
    "                code_lenght2 = df_observations_states[session_id].iloc[index2]['Measurements']['documentLength']\n",
    "                suggestion_lenght = df_observations_states[session_id].iloc[index2]['Measurements']['compCharLen']\n",
    "                if abs(code_lenght2 + suggestion_lenght - code_lenght)<=3:\n",
    "                    df_observations_states[session_id].iloc[index,df_observations_states[session_id].columns.get_loc('HiddenState')]= 'UserPaused'\n",
    "                    break\n",
    "                else:\n",
    "                    df_observations_states[session_id].iloc[index,df_observations_states[session_id].columns.get_loc('HiddenState')]= 'UserTyping'\n",
    "                    break\n",
    "\n",
    "# create observable state diagram\n",
    "column_names = [\"TimeGenerated\", \"CompletionId\", \"UserId\", \"SessionId\",\"StateName\", \"HiddenState\", \"TimeSpentInState\",\"CurrentSuggestion\", \"CurrentPrompt\", \"Measurements\"]\n",
    "unique_session_ids = np.unique(df_logs.SessionID) # or SessionId  \n",
    "\n",
    "index_session = 0\n",
    "for id_unique in tqdm(unique_session_ids):\n",
    "    # split on SessionID\n",
    "    df_task = df_logs[df_logs.SessionID == id_unique]        \n",
    "    # get all completion ids for df_task\n",
    "    completion_ids = df_task.CompletionId.to_numpy()\n",
    "    completion_ids = np.unique(completion_ids)\n",
    "    for completion_id in completion_ids:\n",
    "        df_completion = df_task[df_task.CompletionId == completion_id]\n",
    "        # iterate through df_completion\n",
    "        last_timeout = 0\n",
    "        for index, row in df_completion.iterrows():\n",
    "            name = row['Name']\n",
    "            completion_id = row['CompletionId']\n",
    "            if name != 'copilot/ghostText.stillInCode':\n",
    "                continue\n",
    "            timeout_time = row['MeasurementsJson']['timeout']\n",
    "            # Only do it for small timeouts, otherwise too imprecise\n",
    "            if timeout_time  > 30:\n",
    "                continue\n",
    "            timestamp = row['TimeGenerated']\n",
    "            got_edited = False\n",
    "            # TO-DO: EDITING THRESHOLD FIX\n",
    "            if row['MeasurementsJson']['relativeLexEditDistance'] > 0.15:\n",
    "                got_edited = True\n",
    "            end_time = pd.to_datetime(timestamp)\n",
    "            # add to start time the timeout time\n",
    "            start_time = end_time - pd.Timedelta(seconds=timeout_time) + pd.Timedelta(seconds=last_timeout)\n",
    "            # iterate through df_observations_states[index_session]\n",
    "            for index2 in range(len(df_observations_states[index_session])):\n",
    "                if df_observations_states[index_session].iloc[index2]['HiddenState'] == 'UserTyping':\n",
    "                    difference_start = pd.to_datetime(df_observations_states[index_session].iloc[index2]['TimeGenerated']) - start_time\n",
    "                    difference_end = pd.to_datetime(df_observations_states[index_session].iloc[index2]['TimeGenerated']) - end_time\n",
    "                    difference_start = difference_start.total_seconds()\n",
    "                    difference_end = difference_end.total_seconds()\n",
    "                    if  difference_start >= 0 and difference_end <= 0:\n",
    "                        df_observations_states[index_session].iloc[index2,df_observations_states[index_session].columns.get_loc('HiddenState')] = 'EditingSuggestions'\n",
    "\n",
    "            # if suggestion got edited, assume suggestion won't get edited again, so stop assigning attribution for this suggestion. \n",
    "            if got_edited:\n",
    "                break\n",
    "            last_timeout = timeout_time\n",
    "    index_session += 1\n",
    "\n",
    "# add editDistance\n",
    "for session_id in range(len(df_observations_states)):\n",
    "    EditPercentage = []\n",
    "    # iterate through dataframe and modify statename\n",
    "    for index in range(len(df_observations_states[session_id])):\n",
    "        # get completion id\n",
    "        completion_id = df_observations_states[session_id].iloc[index]['CompletionId']\n",
    "        # get all logs in df_logs that have matching completion_id\n",
    "        df_task_completion = df_logs[df_logs.CompletionId == completion_id]\n",
    "        df_task_completion  = df_task_completion[df_task_completion.Name == 'copilot/ghostText.stillInCode']\n",
    "        edit_distance = {'charEditDistance': -1, 'lexEditDistance': -1, 'stillInCodeHeuristic': -1, 'relativeLexEditDistance': 1}\n",
    "        # iterate through df_task_completion\n",
    "        for index2 in range(len(df_task_completion)):\n",
    "            # get measurements\n",
    "            edit_distance['charEditDistance'] = df_task_completion.iloc[index2]['MeasurementsJson']['charEditDistance']\n",
    "            edit_distance['lexEditDistance'] = df_task_completion.iloc[index2]['MeasurementsJson']['lexEditDistance']\n",
    "            edit_distance['stillInCodeHeuristic'] = df_task_completion.iloc[index2]['MeasurementsJson']['stillInCodeHeuristic']\n",
    "            edit_distance['relativeLexEditDistance'] = df_task_completion.iloc[index2]['MeasurementsJson']['relativeLexEditDistance']\n",
    "            if df_task_completion.iloc[index2]['MeasurementsJson']['timeout'] == 600.0:\n",
    "                break\n",
    "\n",
    "        EditPercentage.append(edit_distance)\n",
    "    df_observations_states[session_id]['EditPercentage'] = EditPercentage\n",
    "\n",
    "# Simple heuristic for prompt crafting, check if last prompt was a comment, user looked at suggestion and  accepted or browsed\n",
    "import nltk\n",
    "for session_id in range(len(df_observations_states)):\n",
    "    # iterate through dataframe and modify statename\n",
    "    for index in range(len(df_observations_states[session_id])):\n",
    "        if df_observations_states[session_id].iloc[index]['HiddenState'] in ['EditingSuggestions', 'UserTyping']:\n",
    "            code_lenght = df_observations_states[session_id].iloc[index]['Measurements']['documentLength']\n",
    "            # do a backward search to find the previous typing state\n",
    "            prompt = df_observations_states[session_id].iloc[index]['CurrentPrompt']\n",
    "            # split prompt on //\n",
    "            prompt_split = prompt.split('//')\n",
    "            # get the last part of the prompt\n",
    "            prompt_last = prompt_split[-1]\n",
    "            # check if prompt_last contains #\n",
    "            is_a_comment = False\n",
    "            if '#' in prompt_last:\n",
    "                is_a_comment = True\n",
    "                #df_observations_states[session_id].iloc[index,df_observations_states[session_id].columns.get_loc('StateName')]= 'PromptCrafting'\n",
    "            try:\n",
    "                prev_prompt = df_observations_states[session_id].iloc[index-1]['CurrentPrompt']\n",
    "            except:\n",
    "                continue\n",
    "            #prev_prompt_dist = nltk.edit_distance(prompt, prev_prompt)\n",
    "            if prev_prompt == prompt:\n",
    "                continue\n",
    "            user_spent_time_looking = df_observations_states[session_id].iloc[index]['TimeSpentInState']\n",
    "            # in two states\n",
    "            try:\n",
    "                user_action = df_observations_states[session_id].iloc[index+3][\"StateName\"]\n",
    "            except:\n",
    "                user_action = 'Undefined'\n",
    "            # edit the time \n",
    "            if is_a_comment and user_spent_time_looking > 0.3 and user_action in ['Accepted', 'Browsing']:\n",
    "                df_observations_states[session_id].iloc[index,df_observations_states[session_id].columns.get_loc('HiddenState')] = 'PromptCrafting'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41.0, 41.0, 41.0, 41.0, 83.0, 83.0, 88.0, 88.0, 284.0, 284.0, 311.0, 311.0, 300.0, 300.0, 27.0, 27.0, 27.0, 37.0, 37.0, 37.0, 27.0, 27.0, 288.0, 288.0, 461.0, 461.0, 510.0, 510.0, 560.0, 560.0]\n"
     ]
    }
   ],
   "source": [
    "print([df_observations_states[7].Measurements.iloc[i]['documentLength'] for i in range(len(df_observations_states[6]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_observations_states[6])):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(df_observations_states, open(extented_model_path, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unobservable States: User Before Action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dag {\n",
    "bb=\"0,0,1,1\"\n",
    "\"Browse Suggestions\" [pos=\"0.874,0.794\"]\n",
    "\"Deferring thought\" [latent,pos=\"0.851,0.401\"]\n",
    "\"Editing Suggestion\" [latent,pos=\"0.177,0.099\"]\n",
    "\"Ghost Text Appears\" [pos=\"0.656,0.176\"]\n",
    "\"Thinking about suggestion\" [latent,pos=\"0.838,0.263\"]\n",
    "\"User Accepts Ghost Text\" [outcome,pos=\"0.434,0.742\"]\n",
    "\"User Before Action\" [pos=\"0.608,0.433\"]\n",
    "\"User Rejects Ghost Text\" [outcome,pos=\"0.642,0.805\"]\n",
    "\"User Typing/Paused\" [pos=\"0.184,0.632\"]\n",
    "\"Writing New Code\" [latent,pos=\"0.326,0.194\"]\n",
    "\"no thought\" [latent,pos=\"0.848,0.567\"]\n",
    "Paused [pos=\"0.318,0.405\"]\n",
    "Typing [pos=\"0.124,0.405\"]\n",
    "\"Browse Suggestions\" -> \"Ghost Text Appears\"\n",
    "\"Deferring thought\" <-> \"User Before Action\"\n",
    "\"Editing Suggestion\" -> \"Ghost Text Appears\"\n",
    "\"Ghost Text Appears\" -> \"User Before Action\"\n",
    "\"Thinking about suggestion\" <-> \"User Before Action\"\n",
    "\"User Accepts Ghost Text\" -> \"User Typing/Paused\"\n",
    "\"User Before Action\" -> \"Browse Suggestions\" [pos=\"0.715,0.611\"]\n",
    "\"User Before Action\" -> \"User Accepts Ghost Text\"\n",
    "\"User Before Action\" -> \"User Rejects Ghost Text\"\n",
    "\"User Before Action\" <-> \"no thought\"\n",
    "\"User Rejects Ghost Text\" -> \"User Typing/Paused\"\n",
    "\"User Typing/Paused\" -> Paused\n",
    "\"User Typing/Paused\" -> Typing\n",
    "\"Writing New Code\" -> \"Ghost Text Appears\"\n",
    "Paused -> \"Ghost Text Appears\"\n",
    "Typing -> \"Editing Suggestion\"\n",
    "Typing -> \"Writing New Code\"\n",
    "}\n",
    "](images/dagitty-model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will decode the User Before Action state. \n",
    "Our strategy will be to define heuristics for decoding for a couple of states. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heuristic coverage:  24.818366753850622\n"
     ]
    }
   ],
   "source": [
    "# we will define one step heuristics first\n",
    "# we define heuristics as a function of a span of logs, or a single entry\n",
    "class Heuristics:\n",
    "    def __init__(self, observed_states = None, unobserved_decoding = None):\n",
    "        self.observed_states = 'UserBeforeAction'\n",
    "        self.unobserved_decoding = ['NoThought', 'UserThinkingSuggestion', 'DeferringThought']\n",
    "\n",
    "    def label_state(self, logs_session, index):\n",
    "        # function documentation input or output\n",
    "        # logs_session: dataframe of logs for a single session\n",
    "        # index: index of the current state\n",
    "        # return: label of the state, or -1 if no heuristic applies\n",
    "\n",
    "        if logs_session.iloc[index]['HiddenState'] not in self.observed_states :\n",
    "             return -1\n",
    "        # call all functions in this class \n",
    "        # if any of the functions return a label, return that label\n",
    "        for function in dir(self):\n",
    "            if function.startswith('heuristic'):\n",
    "                label = getattr(self, function)(logs_session, index)\n",
    "                if label != -1:\n",
    "                    return label\n",
    "        # if no heuristic applies, return -1\n",
    "        return -1\n",
    "        \n",
    "    \n",
    "    def heuristic01_uba(self, logs_session, index):\n",
    "        try:\n",
    "            row = logs_session.iloc[index]\n",
    "            #next_row = logs_session.iloc[index+1]\n",
    "            # no thought: single line rejected \n",
    "            if row[\"TimeSpentInState\"] <= 0.01 and \\\n",
    "            row[\"Measurements\"][\"compCharLen\"] <= 20 and \\\n",
    "            row[\"Measurements\"][\"numLines\"] == 1 and \\\n",
    "            row[\"StateName\"] in ['Rejected','Browsing']:\n",
    "                return self.unobserved_decoding[0]\n",
    "            else:\n",
    "                return -1\n",
    "        except:\n",
    "            return -1 \n",
    "    def heuristic02_uba(self, logs_session, index):\n",
    "        try:\n",
    "            row = logs_session.iloc[index]\n",
    "            #next_row = logs_session.iloc[index+1]\n",
    "            # no thought: multi line accepted in little time and not edited later\n",
    "            if row[\"TimeSpentInState\"] <= 0.3 and \\\n",
    "            row[\"Measurements\"][\"numLines\"] > 2 and \\\n",
    "            row[\"StateName\"] == 'Accepted' and \\\n",
    "            row['EditPercentage']['relativeLexEditDistance'] <= 0.1:          \n",
    "                return self.unobserved_decoding[0]\n",
    "            else:\n",
    "                return -1\n",
    "        except:\n",
    "            return -1 \n",
    "\n",
    "    \n",
    "    def heuristic11_uba(self, logs_session, index):\n",
    "        # thinking about suggestion, significant time spent looking, and suggestion was not edited in the future and accepted.\n",
    "        try:\n",
    "            row = logs_session.iloc[index]\n",
    "            next_row = logs_session.iloc[index+1]   \n",
    "            if row[\"TimeSpentInState\"] >= 5 and \\\n",
    "                row[\"StateName\"] == 'Accepted' and \\\n",
    "                row['EditPercentage']['relativeLexEditDistance']  <= 0.1:          \n",
    "                return self.unobserved_decoding[1]\n",
    "            else:\n",
    "                return -1\n",
    "        except:\n",
    "            return -1 \n",
    "    def heuristic12_uba(self, logs_session, index):\n",
    "        # thinking about suggestion, significant time spent looking, then rejected, and then typed next state\n",
    "        row = logs_session.iloc[index]\n",
    "        try:\n",
    "            next_row = logs_session.iloc[index+1] \n",
    "            #next_next_row = logs_session.iloc[index+2]\n",
    "            if row[\"TimeSpentInState\"] >= 5 and \\\n",
    "                row[\"StateName\"] == 'Rejected' and \\\n",
    "                next_row[\"HiddenState\"] in ['EditingSuggestions', 'UserTyping']:\n",
    "                return self.unobserved_decoding[1]\n",
    "            else:\n",
    "                return -1\n",
    "        except:\n",
    "            return -1 \n",
    "    def heuristic21_uba(self, logs_session, index):\n",
    "        # defer thought for later: 2 or more previous actions were accepts, all single line, all accepts\n",
    "        ''' \n",
    "        Sample log behavior\n",
    "        UserBeforeAction', 'Accepted', 'UserPaused', 'Shown',\n",
    "       'UserBeforeAction', 'Accepted', 'UserPaused', 'Shown',\n",
    "       'UserBeforeAction', 'Accepted', 'UserPaused', 'Shown',\n",
    "        ''' \n",
    "        try:\n",
    "            prev_rows_states = logs_session.iloc[index-4:index].StateName.to_numpy() # -3 and -7 should be accepts\n",
    "            prev_rows_hidden_states = logs_session.iloc[index-4:index].HiddenState.to_numpy() # -3 and -7 should be accepts\n",
    "\n",
    "            row = logs_session.iloc[index]\n",
    "            next_row = logs_session.iloc[index+1]\n",
    "            prev_state_condition =  ['Accepted', 'Shown', 'Accepted', 'Shown']\n",
    "            prev_hidden_state_condition =  ['UserBeforeAction', 'UserPaused', 'UserBeforeAction', 'UserPaused']\n",
    "            prev_hidden_state_check = True\n",
    "            prev_state_check = True\n",
    "            # enumerate through prev_rows_states\n",
    "            counter = 0\n",
    "            for i in range(len(prev_state_condition)):\n",
    "                if prev_rows_states[i] != prev_state_condition[counter]:\n",
    "                    prev_state_check = False\n",
    "                    break\n",
    "                if prev_hidden_state_condition[i] == 'UserPaused' and prev_rows_hidden_states[i] != prev_hidden_state_condition[counter]:\n",
    "                    prev_hidden_state_check = False\n",
    "                    break\n",
    "                counter += 1\n",
    "            if row[\"TimeSpentInState\"] <= 1 and \\\n",
    "            row[\"Measurements\"][\"numLines\"] == 1 and \\\n",
    "            row[\"StateName\"] == 'Accepted' and \\\n",
    "            prev_state_check and prev_hidden_state_check:\n",
    "                return self.unobserved_decoding[2]\n",
    "            else:\n",
    "                return -1\n",
    "        except:\n",
    "            return -1\n",
    "\n",
    "    def heuristic22_uba(self, logs_session, index):\n",
    "        # defer thought for later: 1 big multi line suggestion that got edited signifcantly later\n",
    "        try:\n",
    "            row = logs_session.iloc[index]\n",
    "            #next_row = logs_session.iloc[index+1]\n",
    "            # no thought: multi line accepted in little time and not edited later\n",
    "            if row[\"TimeSpentInState\"] <= 0.3 and \\\n",
    "            row[\"Measurements\"][\"numLines\"] > 2 and \\\n",
    "            row[\"StateName\"] == 'Accepted' and \\\n",
    "            row['EditPercentage']['relativeLexEditDistance'] > 0.3:          \n",
    "                return self.unobserved_decoding[2]\n",
    "            else:\n",
    "                return -1\n",
    "        except:\n",
    "            return -1\n",
    "            \n",
    "# Apply Heuristics to the dataframe\n",
    "heuristics_uba = Heuristics()\n",
    "heuristic_coverage = 0\n",
    "heuristic_could_apply = 0\n",
    "for session_id in range(len(df_observations_states)):\n",
    "    # iterate through dataframe and modify statename\n",
    "    for index in range(len(df_observations_states[session_id])):\n",
    "        heuristic_label = heuristics_uba.label_state(df_observations_states[session_id], index)\n",
    "        if heuristic_label != -1:\n",
    "            df_observations_states[session_id].iloc[index,df_observations_states[session_id].columns.get_loc('HiddenState')] = heuristic_label\n",
    "            heuristic_coverage += 1\n",
    "        # check if state name is userbeforeaction\n",
    "        if df_observations_states[session_id].iloc[index]['HiddenState'] == 'UserBeforeAction':\n",
    "            heuristic_could_apply += 1\n",
    "print('Heuristic coverage: ', heuristic_coverage/heuristic_could_apply*100)\n",
    "# 15 percent coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_states = 'UserBeforeAction'\n",
    "unobserved_decoding = ['NoThought', 'UserThinkingSuggestion', 'DeferringThought']\n",
    "state_encoding_dict = {\n",
    "    'Accepted': 1, # first action after UBA\n",
    "    'Rejected': 0,\n",
    "    'Browsing':  2,\n",
    "    'EditingSuggestions': 1,\n",
    "    'UserTyping': 1, # second action after UBA\n",
    "    'PromptCrafting': 1,\n",
    "    'Shown' : 2,\n",
    "    'UserPaused': 0,\n",
    "    'UserTypingOrPaused': 0\n",
    "}\n",
    "heuristic_encoding_dict = {\n",
    "    'NoThought': 0,\n",
    "    'UserThinkingSuggestion': 1,\n",
    "    'DeferringThought': 2\n",
    "}\n",
    "observation_sequences = []\n",
    "observation_feature_names = [ 'charLen', 'confidence', 'numLines',  'timeSpentInState', 'relativeLexEditDistance', 'next action', 'next-next action', 'heuristic']\n",
    "\n",
    "def get_observation_sequence(logs_session):\n",
    "    session_observations = []\n",
    "    for index in range(len(logs_session)):\n",
    "        row = logs_session.iloc[index]\n",
    "        if logs_session.iloc[index]['StateName'] == observed_states or \\\n",
    "           logs_session.iloc[index]['StateName'] in unobserved_decoding:\n",
    "            # collect all features for the observation\n",
    "            observation = []\n",
    "            # add next two states\n",
    "            state_names = []\n",
    "            try:\n",
    "                state_names.append(logs_session.iloc[index+1]['StateName'])\n",
    "                state_names.append(logs_session.iloc[index+2]['StateName'])\n",
    "            except:\n",
    "                state_names = []\n",
    "                state_names.append('NAN')\n",
    "                state_names.append('NAN')\n",
    "            # encode the state names according to state_encoding_dict\n",
    "            state_names_encoded = []\n",
    "            for state_name in state_names:\n",
    "                try:\n",
    "                    state_names_encoded.append(state_encoding_dict[state_name])\n",
    "                except:\n",
    "                    state_names_encoded.append(0)\n",
    "            # add suggestion features\n",
    "            try:\n",
    "                suggestion_features = [row['Measurements']['compCharLen'],\n",
    "                                    row['Measurements']['confidence'],\n",
    "                                    row['Measurements']['numLines']]\n",
    "            except:\n",
    "                suggestion_features = [0, 0, 0]\n",
    "            time_spent_in_state = row['TimeSpentInState']\n",
    "            edit_distance = max(row['EditPercentage']['relativeLexEditDistance'],0)\n",
    "            # add heuristic\n",
    "            heuristic = np.nan\n",
    "            if row['StateName'] in unobserved_decoding:\n",
    "                heuristic =  heuristic_encoding_dict[row['StateName']]\n",
    "            observation.extend(suggestion_features)\n",
    "            observation.append(time_spent_in_state)\n",
    "            observation.append(edit_distance)\n",
    "            observation.extend(state_names_encoded)\n",
    "            observation.append(heuristic)\n",
    "            # make observation into numeric np array\n",
    "            observation = np.array(observation, dtype=np.float32)\n",
    "        \n",
    "            session_observations.append(observation)\n",
    "    return session_observations\n",
    "\n",
    "for session_id in range(len(df_observations_states)):\n",
    "    # iterate through dataframe and modify statename\n",
    "    session_observations = get_observation_sequence(df_observations_states[session_id])\n",
    "    if len(session_observations) > 1:\n",
    "        observation_sequences.append(np.array(session_observations, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a HeterogeneousHMM object\n",
    "my_hmm = HeterogeneousHMM(\n",
    "        n_states=3,\n",
    "        n_g_emissions=5,\n",
    "        n_d_emissions=3,\n",
    "        n_d_features=[3, 3, 3],\n",
    "        covariance_type='full',\n",
    "        nr_no_train_de=1,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "my_hmm.B =  [1/3*np.ones((3,3)), 1/3*np.ones((3,3)),  0.8*np.eye(3) + 0.1*np.ones((3,3))]\n",
    "\n",
    "# train the model to estimate the parameters\n",
    "my_hmm, log_likelihood = my_hmm.train(\n",
    "    observation_sequences, n_init=1, n_iter=100, conv_thresh=0.001, conv_iter=5, plot_log_likelihood=True,\n",
    ")\n",
    "\n",
    "# print model parameters\n",
    "hu.pretty_print_hmm(my_hmm, hmm_type='Heterogeneous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode a training sequences\n",
    "index_session = 31\n",
    "logL, state_seq = my_hmm.decode([observation_sequences[index_session]], algorithm='viterbi')\n",
    "state_names = ['DeferringThought', 'UserThinkingSuggestion', 'NoThought']\n",
    "hu.plot_decode(\n",
    "    observation_sequences[index_session], \n",
    "    observation_feature_names, \n",
    "    state_seq[0], \n",
    "    discrete_columns=[ 'next action',' next-next action'], \n",
    "    #time_stamps=df[df['seq_no'] == 0]['date'],\n",
    "    figsize=(15, 10),\n",
    "    state_names = state_names,\n",
    "    filename = 'plots_hmm.pdf'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we transform back the df_observation_states from the deocding\n",
    "for session_id in range(len(df_observations_states)):\n",
    "    # iterate through dataframe and modify statename\n",
    "    session_observations = get_observation_sequence(df_observations_states[session_id])\n",
    "    if len(session_observations) < 1:\n",
    "        continue\n",
    "    # decode session\n",
    "    logL, state_seq = my_hmm.decode([session_observations], algorithm='viterbi')\n",
    "    # transform back the state_seq to the original state names\n",
    "    state_seq_names = [state_names[i] for i in state_seq[0]]\n",
    "    # iterate through dataframe\n",
    "    counter = 0\n",
    "    for index in range(len(df_observations_states[session_id])):\n",
    "        row = df_observations_states[session_id].iloc[index]\n",
    "        if row['StateName'] == observed_states or \\\n",
    "           row['StateName'] in unobserved_decoding:\n",
    "            df_observations_states[session_id].iloc[index,df_observations_states[session_id].columns.get_loc('StateName')] = state_seq_names[counter]\n",
    "            counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(df_observations_states, open(extented_model_path, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/microsoft/codebert-base\n",
    "# can get code embeddings cheaply\n",
    "#from sentence_transformers import SentenceTransformer\n",
    "#sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "#model = SentenceTransformer('flax-sentence-embeddings/st-codesearch-distilroberta-base')\n",
    "#embeddings = model.encode(sentences)\n",
    "#print(embeddings.size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract for video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "extented_model_path = 'data/generated_data/df_obs_states_7-03.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_observations_states[37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"import numpy as np\"\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#item = 'mean = sum(array) / len(array)'\n",
    "item = \"import numpy as np\"\n",
    "#item = \"model\"\n",
    "\n",
    "array = df_observations_states[37].CurrentSuggestion.to_numpy()\n",
    "# check if item is substring of array element\n",
    "first_index = 0\n",
    "for i in range(len(array)):\n",
    "    if item in array[i]:\n",
    "        print(array[i])\n",
    "        first_index = i\n",
    "        break\n",
    "print(first_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_video_states =df_observations_states[37][first_index:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(df_video_states, open(extented_model_path, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode each unique string in state_names as a number\n",
    "# import labelencoder\n",
    "from sklearn import preprocessing\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "encoder.fit(state_names)\n",
    "encoded_state_names = encoder.transform(state_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_state_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = hmm.MultinomialHMM(8, verbose=True)\n",
    "model.fit(encoded_state_names.reshape(1, -1))\n",
    "model.score(encoded_state_names.reshape(1, -1))\n",
    "model.decode(encoded_state_names.reshape(1, -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmmviz import TransGraph\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "T = pd.crosstab(\n",
    "    pd.Series(state_names[:-1], name='Today'),\n",
    "    pd.Series(state_names[1:], name='Tomorrow'),\n",
    "    normalize=0\n",
    ")\n",
    "\n",
    "\n",
    "graph = TransGraph(T)\n",
    "\n",
    "# looks best on square figures/axes\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "\n",
    "graph.draw()\n",
    "plt.savefig('hmm_graph.pdf')\n",
    "plt.show()\n",
    "# save plot as pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmmviz import TransGraph\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "T = pd.crosstab(\n",
    "    pd.Series(state_names[:-1], name='Today'),\n",
    "    pd.Series(state_names[1:], name='Tomorrow'),\n",
    "    normalize=0\n",
    ")\n",
    "\n",
    "\n",
    "graph = TransGraph(T)\n",
    "\n",
    "# looks best on square figures/axes\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "\n",
    "graph.draw()\n",
    "plt.savefig('hmm_graph.pdf')\n",
    "plt.show()\n",
    "# save plot as pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e710af216e809473b1f2bcdee939ed3d8fc69fba0a18fe13b179176696cffea0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('hussein')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
