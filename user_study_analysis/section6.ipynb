{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "import copy\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import logging\n",
    "import math\n",
    "import matplotlib\n",
    "from re import S\n",
    "import collections\n",
    "from hmmviz import TransGraph\n",
    "from scipy.stats.stats import pearsonr  \n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='sans-serif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('../data/data_labeled_study.pkl', 'rb') as f:\n",
    "    logs_by_user_session_labeled = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 6.1: Time Spent in various CUPSs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For figures 6a and 6c, please see the notebooks viz_draw.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 6b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states = []\n",
    "all_actions = []\n",
    "all_times = []\n",
    "all_states_continuous = []\n",
    "all_states_list = []\n",
    "all_times_list = []\n",
    "\n",
    "all_times_continuous = []\n",
    "for i in range(len(logs_by_user_session_labeled)):\n",
    "    states = logs_by_user_session_labeled[i].LabeledState.to_numpy()\n",
    "    actions = logs_by_user_session_labeled[i].StateName.to_numpy()\n",
    "    times = logs_by_user_session_labeled[i].TimeSpentInState.to_numpy()\n",
    "    # clean up states\n",
    "    for j in range(len(states)):\n",
    "        if states[j] == 'Edditing Last Suggestion (X)':\n",
    "            states[j] = 'Editing Last Suggestion (X)'\n",
    "        if states[j] == 'IDK':\n",
    "            states[j] = 'IDK (I)'\n",
    "        if states[j] == 'Looking up documentation' or states[j] == 'Looking up documentation (N)':\n",
    "            states[j] = 'Looking up Documentation (N)'\n",
    "        if states[j] == 'h':\n",
    "            states[j] = 'Thinking About New Code To Write (F)'\n",
    "        if states[j] == 'Thinking about new code to write (F)':\n",
    "            states[j] = 'Thinking About New Code To Write (F)'\n",
    "\n",
    "    # get indices where state is IDK\n",
    "    idk_indices = [i for i in range(len(states)) if states[i] == 'IDK (I)']\n",
    "    states = [states[i] for i in range(len(states)) if i not in idk_indices]\n",
    "    actions = [actions[i] for i in range(len(actions)) if i not in idk_indices]\n",
    "    times = [times[i] for i in range(len(times)) if i not in idk_indices]\n",
    "\n",
    "    states_continuous = []\n",
    "    times_continuous = []\n",
    "    # merge states with same name\n",
    "    last_state = states[0]\n",
    "    times_cumalitive = 0\n",
    "    for i in range(len(states)):\n",
    "        if states[i] != last_state:\n",
    "            states_continuous.append(last_state)\n",
    "            last_state = states[i]\n",
    "            times_continuous.append(times_cumalitive)\n",
    "            times_cumalitive = times[i]\n",
    "        else:\n",
    "            times_cumalitive += times[i]\n",
    "    states_continuous.append(last_state)\n",
    "    times_continuous.append(times_cumalitive)\n",
    "    \n",
    "    all_states_list.extend(states)\n",
    "    all_times_list.extend(times)\n",
    "    all_states_continuous.extend(states_continuous)\n",
    "    all_times_continuous.extend(times_continuous)\n",
    "    all_states.append(states)\n",
    "    all_actions.append(actions)\n",
    "    all_times.append(times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_unique = list(set(all_states_continuous))\n",
    "# for each session, count how many times each state is used\n",
    "\n",
    "states_count = [[0 for i in range(len(states_unique))] for _ in range(len(all_states))]\n",
    "for i in range(len(all_states)):\n",
    "    for j in range(len(all_states[i])):\n",
    "        states_count[i][states_unique.index(all_states[i][j])] += all_times[i][j]\n",
    "# normalize\n",
    "states_count = [[i/sum(states_count_single)*100 for i in states_count_single] for states_count_single in states_count]\n",
    "averaged_over_users = np.mean(states_count, axis=0)\n",
    "# print\n",
    "print('Averaged Across Users \\n \\n')\n",
    "for i in range(len(states_unique)):\n",
    "    print(f' {states_unique[i]}  {averaged_over_users[i]:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_unique = list(set(all_states_continuous))\n",
    "# for each session, count how many times each state is used\n",
    "states_count = [0 for i in range(len(states_unique))]\n",
    "states_freq = {}\n",
    "for i in range(len(all_states)):\n",
    "    for j in range(len(all_states[i])):\n",
    "        states_count[states_unique.index(all_states[i][j])] += all_times[i][j]\n",
    "# normalize\n",
    "states_count = [i/sum(states_count)*100 for i in states_count]\n",
    "print('Averaged Across All Sessions \\n \\n')\n",
    "for i in range(len(states_count)):\n",
    "    print(f' {states_unique[i]}  {states_count[i]:.2f}')\n",
    "    states_freq[states_unique[i]] = states_count[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique states\n",
    "from scipy import stats as st\n",
    "\n",
    "states_unique = list(set(all_states_continuous))\n",
    "# for each state get average time spent in state\n",
    "all_states_list\n",
    "states_time = {}\n",
    "for i in range(len(all_states_list)):\n",
    "    # check if already in dict\n",
    "    if all_states_list[i] in states_time:\n",
    "        states_time[all_states_list[i]].append(all_times_list[i])\n",
    "    else:\n",
    "        states_time[all_states_list[i]] = [all_times_list[i]]\n",
    "# get average time spent in state\n",
    "states_time_avg = {}\n",
    "for s in states_time:\n",
    "    # get 90% confidence interval for states_time[s] which is a list of times\n",
    "    confidence_interval = st.t.interval(0.90, len(states_time[s])-1, loc=np.mean(states_time[s]), scale=st.sem(states_time[s]))\n",
    "    states_time_avg[s] = [np.mean(states_time[s]), np.median(states_time[s]), np.std(states_time[s]), confidence_interval]\n",
    "# sort states by average time spent in state\n",
    "# print\n",
    "for s in states_time_avg:\n",
    "    print(f' state {s} avg time {states_time_avg[s][0]:.2f} median time {states_time_avg[s][1]:.2f} std time {states_time_avg[s][2]:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmmviz import TransGraph\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "T = pd.crosstab(\n",
    "    pd.Series(all_states_list[:-1], name='Today'),\n",
    "    pd.Series(all_states_list[1:], name='Tomorrow'),\n",
    "    normalize=0\n",
    ")\n",
    "'''\n",
    "T = pd.crosstab(\n",
    "    pd.Series(all_states_continuous[:-1], name='Today'),\n",
    "    pd.Series(all_states_continuous[1:], name='Tomorrow'),\n",
    "    normalize=0\n",
    ")\n",
    "'''\n",
    "graph = TransGraph(T)\n",
    "transition_matrix = np.array(graph.dataframe)\n",
    "nodes = list(graph.dataframe.index)\n",
    "# take each string in nodes and add new line if more than 2 words in string\n",
    "nodes_new = []\n",
    "for i in range(len(nodes)):\n",
    "    if len(nodes[i].split(' ')) > 2:\n",
    "        words = nodes[i].split(' ')\n",
    "        temp_str = ''\n",
    "        added_line = False\n",
    "        for j in range(len(words)-1):\n",
    "            temp_str += words[j] +' ' \n",
    "            if (j == 1 or len(temp_str)> 15) and not added_line:\n",
    "                temp_str += '\\n'\n",
    "                added_line = True\n",
    "        nodes_new.append(temp_str)\n",
    "    else:\n",
    "        nodes_new.append(nodes[i])\n",
    "nodes = nodes_new\n",
    "nodes[3] = 'Editing Written \\n Code'\n",
    "nodes[-2] = 'Writing \\n Documentation '\n",
    "labels_nodes = {}\n",
    "# color nodes\n",
    "frequencies = [11.31, 1.39, 11.9,4.28,7.45,0.01,11.56,10.91,22.4,4.2,0.53,14.05]\n",
    "avg_times = [29.24,  7.34, 24.22, 14.08, 106.51, 11.08, 10.67, 19.67, 10.58, 10.54,  9.12, 13.60]\n",
    "for i in range(len(nodes)):\n",
    "    #nodes[i] = nodes[i] + f' \\n {avg_times[i]:.2f}s , {frequencies[i]:.2f}per ' \n",
    "    labels_nodes[nodes[i]] = f\"{nodes[i]}\"#  \\n {avg_times[i]:.2f}s, {frequencies[i]:.2f}/100 \" \n",
    "# permute array nodes given new indices\n",
    "new_permutation = [0,4,1,8,7,5,9,11,3,2,10,6] # list(range(12))#\n",
    "nodes = [nodes[i] for i in new_permutation]\n",
    "# new permutation is the new order for nodes\n",
    "# make new transition matrix that is consistent with new permutation\n",
    "transition_matrix_new = np.zeros((len(nodes),len(nodes)))\n",
    "for i in range(len(nodes)):\n",
    "    for j in range(len(nodes)):\n",
    "        transition_matrix_new[i][j] = transition_matrix[new_permutation[i]][new_permutation[j]]\n",
    "transition_matrix = transition_matrix_new\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "cset = namedtuple('Mcset',\n",
    "            'rose indigo sand green cyan wine teal olive purple pale_grey black white yellow')\n",
    "colors = cset('#CC6677', '#332288', '#DDCC77', '#117733', '#88CCEE',\n",
    "            '#882255', '#44AA99', '#999933', '#AA4499', '#DDDDDD',\n",
    "            '#000000', '#FFFFFF', '#DDAA33')\n",
    "\n",
    "color_mapping = {'Debugging/Testing Code (H)': colors.yellow, 'Deferring Thought For Later (D)': colors.cyan, 'Editing Last Suggestion (X)': colors.rose, 'Editing Written Code(C)': colors.purple, 'Looking up Documentation (N)': colors.olive, 'Not Thinking': colors.white,  'Prompt Crafting (V)': colors.indigo, 'Thinking About New Code To Write (F)': colors.teal, 'Thinking/Verifying Suggestion (A)': colors.green, 'Waiting For Suggestion (G)': colors.pale_grey, 'Writing Documentation (B)': colors.sand, 'Writing New Functionality (Z)': colors.wine}\n",
    "nodes_colors = list(color_mapping.values())\n",
    "edgecolors  = {k: colors.black for k in color_mapping.keys()}\n",
    "nodes_colors = [nodes_colors[i] for i in new_permutation]\n",
    "\n",
    "\n",
    "color_mapping['Not Thinking (S)'] = '#FFFFFF'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import W\n",
    "# sort statesfreq by frequency\n",
    "statesfreq = sorted(states_freq.items(), key=lambda x: x[1], reverse=False)\n",
    "# get keys sorted\n",
    "statesfreq_keys = [x[0] for x in statesfreq]\n",
    "print(statesfreq_keys)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "ax1 = plt.subplot(1,1,1)\n",
    "y = np.arange(12)*2\n",
    "w = 0.5\n",
    "plt.yticks(y  , statesfreq_keys, rotation='horizontal')\n",
    "error_bars = [(states_time_avg[s][3][1]-states_time_avg[s][3][0])/2 for s in statesfreq_keys]\n",
    "\n",
    "freq = ax1.barh(y , [states_freq[s] for s in statesfreq_keys],align='edge',  alpha=1,  height = 2*w, color=[color_mapping[s] for s in statesfreq_keys], edgecolor ='black')\n",
    "\n",
    "#time = ax1.barh(y , [states_time_avg[s][0] for s in statesfreq_keys], align='edge', xerr= error_bars,   height = w,  color=[color_mapping[s] for s in statesfreq_keys], edgecolor ='black', )\n",
    "#ax2 = ax1.twiny()\n",
    "ax1.set_xlabel('\\% of Session spent in State', fontsize=20)\n",
    "\n",
    "# change font size of x axis\n",
    "ax1.tick_params(axis='y', labelsize=20)\n",
    "ax1.tick_params(axis='x', labelsize=20)\n",
    "# make limit of x axis the same and 0\n",
    "ax1.set_xlim(0, 30)\n",
    "# more ticks for ax2\n",
    "ax1.set_xticks(np.arange(0, 30, 5))\n",
    "# axis titles\n",
    "# legend\n",
    "# show vertical lines\n",
    "\n",
    "ax1.axvline(x=5, color='black', linestyle='--', alpha=0.2)\n",
    "ax1.axvline(x=10, color='black', linestyle='--', alpha=0.2)\n",
    "ax1.axvline(x=15, color='black', linestyle='--', alpha=0.2)\n",
    "ax1.axvline(x=20, color='black', linestyle='--', alpha=0.2)\n",
    "ax1.axvline(x=25, color='black', linestyle='--', alpha=0.2)\n",
    "ax1.axvline(x=30, color='black', linestyle='--', alpha=0.2)\n",
    "ax1.axvline(x=35, color='black', linestyle='--', alpha=0.2)\n",
    "ax1.axvline(x=40, color='black', linestyle='--', alpha=0.2)\n",
    "ax1.axvline(x=45, color='black', linestyle='--', alpha=0.2)\n",
    "ax1.axvline(x=50, color='black', linestyle='--', alpha=0.2)\n",
    "ax1.axvline(x=55, color='black', linestyle='--', alpha=0.2)\n",
    "ax1.axvline(x=60, color='black', linestyle='--', alpha=0.2)\n",
    "\n",
    "#plt.legend([time, freq],['Average Time in State', 'Frequency'], fontsize=20)\n",
    "# save with tight   \n",
    "plt.savefig('histogram.pdf',dpi=1000,  bbox_inches='tight')   \n",
    "\n",
    "# show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time In CUPS states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states = []\n",
    "all_actions = []\n",
    "all_times = []\n",
    "all_states_continuous = []\n",
    "all_states_list = []\n",
    "all_times_list = []\n",
    "\n",
    "all_times_continuous = []\n",
    "for i in range(len(logs_by_user_session_labeled)):\n",
    "    states = logs_by_user_session_labeled[i].LabeledState.to_numpy()\n",
    "    actions = logs_by_user_session_labeled[i].StateName.to_numpy()\n",
    "    times = logs_by_user_session_labeled[i].TimeSpentInState.to_numpy()\n",
    "    # clean up states\n",
    "    for j in range(len(states)):\n",
    "        if states[j] == 'Edditing Last Suggestion (X)':\n",
    "            states[j] = 'Editing Last Suggestion (X)'\n",
    "        if states[j] == 'IDK':\n",
    "            states[j] = 'IDK (I)'\n",
    "        if states[j] == 'Looking up documentation' or states[j] == 'Looking up documentation (N)':\n",
    "            states[j] = 'Looking up Documentation (N)'\n",
    "        if states[j] == 'h':\n",
    "            states[j] = 'Thinking About New Code To Write (F)'\n",
    "        if states[j] == 'Thinking about new code to write (F)':\n",
    "            states[j] = 'Thinking About New Code To Write (F)'\n",
    "\n",
    "    # get indices where state is IDK\n",
    "    idk_indices = [i for i in range(len(states)) if states[i] == 'IDK (I)']\n",
    "    states = [states[i] for i in range(len(states)) if i not in idk_indices]\n",
    "    actions = [actions[i] for i in range(len(actions)) if i not in idk_indices]\n",
    "    times = [times[i] for i in range(len(times)) if i not in idk_indices]\n",
    "\n",
    "    states_continuous = []\n",
    "    times_continuous = []\n",
    "    # merge states with same name\n",
    "    last_state = states[0]\n",
    "    times_cumalitive = 0\n",
    "    for i in range(len(states)):\n",
    "        if states[i] != last_state:\n",
    "            states_continuous.append(last_state)\n",
    "            last_state = states[i]\n",
    "            times_continuous.append(times_cumalitive)\n",
    "            times_cumalitive = times[i]\n",
    "        else:\n",
    "            times_cumalitive += times[i]\n",
    "    states_continuous.append(last_state)\n",
    "    times_continuous.append(times_cumalitive)\n",
    "    \n",
    "    all_states_list.extend(states)\n",
    "    all_times_list.extend(times)\n",
    "    all_states_continuous.extend(states_continuous)\n",
    "    all_times_continuous.extend(times_continuous)\n",
    "    all_states.append(states)\n",
    "    all_actions.append(actions)\n",
    "    all_times.append(times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_unique = list(set(all_states_continuous))\n",
    "# for each session, count how many times each state is used\n",
    "\n",
    "states_count = [[0 for i in range(len(states_unique))] for _ in range(len(all_states))]\n",
    "for i in range(len(all_states)):\n",
    "    for j in range(len(all_states[i])):\n",
    "        states_count[i][states_unique.index(all_states[i][j])] += all_times[i][j]\n",
    "# normalize\n",
    "states_count = [[i/sum(states_count_single)*100 for i in states_count_single] for states_count_single in states_count]\n",
    "averaged_over_users = np.mean(states_count, axis=0)\n",
    "# median\n",
    "median = np.median(states_count, axis=0)\n",
    "# get std\n",
    "std = np.std(states_count, axis=0)\n",
    "# print\n",
    "print('Averaged Across Users \\n \\n')\n",
    "for i in range(len(states_unique)):\n",
    "    print(f' {states_unique[i]}  {averaged_over_users[i]:.2f} {std[i]:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for each participant, see how often is verifying suggestion is the largest state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count for each list in states_count, how often the max is index 7\n",
    "count_top1 = 0\n",
    "count_top3 = 0\n",
    "for i in range(len(states_count)):\n",
    "    if np.argmax(states_count[i]) == 0:\n",
    "        count_top1 += 1\n",
    "        count_top3 += 1\n",
    "    # second argmax is 7\n",
    "    if np.argsort(states_count[i])[-2] == 0:\n",
    "        count_top3 += 1\n",
    "    # third argmax is 7\n",
    "    if np.argsort(states_count[i])[-3] == 0:\n",
    "        count_top3 += 1\n",
    "    #print(states_count[i][7])\n",
    "\n",
    "print(count_top1)\n",
    "print(count_top3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for each participant, see how often is writing code is the largest state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count for writiin\n",
    "count_top1 = 0\n",
    "count_top3 = 0\n",
    "for i in range(len(states_count)):\n",
    "    if np.argmax(states_count[i]) == 8:\n",
    "        count_top1 += 1\n",
    "        count_top3 += 1\n",
    "    # second argmax is 7\n",
    "    if np.argsort(states_count[i])[-2] == 8:\n",
    "        count_top3 += 1\n",
    "    # third argmax is 7\n",
    "    if np.argsort(states_count[i])[-3] == 8:\n",
    "        count_top3 += 1\n",
    "    print(states_count[i][8])\n",
    "print(count_top1)\n",
    "print(count_top3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count how often Copilot states spend their time in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices for copilot 0\n",
    "count_top1 = 0\n",
    "coderec_states_time = []\n",
    "for i in range(len(states_count)):\n",
    "    # sum indices at 1,2,3,5,7 of states_count[i]\n",
    "    sum_coderec_states = sum([states_count[i][0], states_count[i][3], states_count[i][4], states_count[i][10], states_count[i][11]])\n",
    "    print(sum_coderec_states)\n",
    "    coderec_states_time.append(sum_coderec_states)\n",
    "    if sum_coderec_states > 50:\n",
    "        count_top1 += 1\n",
    "\n",
    "print(f'how many more than 47percent {sum(i > 47 for i in coderec_states_time)/len(coderec_states_time)}')\n",
    "print(f'how many more than 21percent {sum(i > 21 for i in coderec_states_time)/len(coderec_states_time)}')\n",
    "\n",
    "print(\"COUNT TOP 1\") \n",
    "print(count_top1)\n",
    "print(np.mean(coderec_states_time))\n",
    "print(np.median(coderec_states_time))\n",
    "print(np.std(coderec_states_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 6.2: behavior by task and experience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_by_user = {'Algorithmic Problem' : [4,17,18], 'Data Manipulation': [1,2,11,20], 'Data Analysis':[5,8], 'Machine Learning':[3,7,12,15], 'Classes':[6,9], 'Writing Tests':[16],'Editing Code':[10,14,21], 'Logistic Regression':[13,19]}\n",
    "\n",
    "\n",
    "all_states = []\n",
    "all_actions = []\n",
    "all_times = []\n",
    "for i in range(len(logs_by_user_session_labeled)):\n",
    "    states = logs_by_user_session_labeled[i].LabeledState.to_numpy()\n",
    "    actions = logs_by_user_session_labeled[i].StateName.to_numpy()\n",
    "    times = logs_by_user_session_labeled[i].TimeSpentInState.to_numpy()\n",
    "    # clean up states\n",
    "    for j in range(len(states)):\n",
    "        if states[j] == 'Edditing Last Suggestion (X)':\n",
    "            states[j] = 'Editing Last Suggestion (X)'\n",
    "        if states[j] == 'IDK':\n",
    "            states[j] = 'IDK (I)'\n",
    "        if states[j] == 'Looking up documentation' or states[j] == 'Looking up documentation (N)':\n",
    "            states[j] = 'Looking up Documentation (N)'\n",
    "        if states[j] == 'h':\n",
    "            states[j] = 'Thinking About New Code To Write (F)'\n",
    "        if states[j] == 'Thinking about new code to write (F)':\n",
    "            states[j] = 'Thinking About New Code To Write (F)'\n",
    "\n",
    "    # get indices where state is IDK\n",
    "    idk_indices = [i for i in range(len(states)) if states[i] == 'IDK (I)']\n",
    "    states = [states[i] for i in range(len(states)) if i not in idk_indices]\n",
    "    actions = [actions[i] for i in range(len(actions)) if i not in idk_indices]\n",
    "    times = [times[i] for i in range(len(times)) if i not in idk_indices]\n",
    "\n",
    "    all_states.append(states)\n",
    "    all_actions.append(actions)\n",
    "    all_times.append(times)\n",
    "all_states_by_task = {}\n",
    "all_actions_by_task = {}\n",
    "all_times_by_task = {}\n",
    "for task in tasks_by_user:\n",
    "    all_states_by_task[task] = []\n",
    "    all_actions_by_task[task] = []\n",
    "    all_times_by_task[task] = []\n",
    "    for i in tasks_by_user[task]:\n",
    "        all_states_by_task[task].extend(all_states[i-1])\n",
    "        all_actions_by_task[task].extend(all_actions[i-1])\n",
    "        all_times_by_task[task].extend(all_times[i-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 0\n",
    "for task in tasks_by_user:\n",
    "    print(task)\n",
    "    z += 1\n",
    "    if z<= 3:\n",
    "        continue\n",
    "    import collections\n",
    "    counter = collections.Counter(all_actions_by_task[task])\n",
    "    # normalize counter\n",
    "    counter_normalized = {k: v/sum(counter.values()) for k, v in counter.items()}\n",
    "    print(counter)\n",
    "    print(f' Accept Rate is {counter[\"Accepted\"]/ counter[\"Shown\"]}')\n",
    "    all_actions_binary = [] \n",
    "    # for each list in all_actions, keep only Accepted and Rejected and convert to binary\n",
    "    # get standard error of bernoulli\n",
    "    # create list of 0s of lenght counter[\"Shown\"]\n",
    "    all_actions_binary = [0]*counter[\"Shown\"]\n",
    "    # add 1s for Accepted\n",
    "    all_actions_binary[:counter[\"Accepted\"]] = [1]*counter[\"Accepted\"]\n",
    "    print(f' Mean is {np.mean(all_actions_binary)}')\n",
    "    task_num_users = len(tasks_by_user[task])\n",
    "    print(f' Standard Error is {np.std(all_actions_binary)/np.sqrt(task_num_users)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi square test to compare means\n",
    "# NOT USED ANYMORE\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "counter_dm = collections.Counter(all_actions_by_task['Data Manipulation'])\n",
    "counter_classes = collections.Counter(all_actions_by_task['Classes'])\n",
    "table = [[counter_dm['Shown'] -counter_dm['Accepted'], counter_dm['Accepted']],[counter_classes['Shown'] -counter_classes['Accepted'], counter_classes['Accepted']]]\n",
    "stat, p, dof, expected = chi2_contingency(table)\n",
    "print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret p-value\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same proportions of accepts (fail to reject H0)')\n",
    "else:\n",
    "    print('Different proportions of accepts (reject H0)')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "time_distrubution_by_task = {}\n",
    "for task in tasks_by_user:\n",
    "    print(f' \\n {task} \\n')\n",
    "\n",
    "    states_unique = list(set(all_states_continuous))\n",
    "# for each session, count how many times each state is used\n",
    "\n",
    "    states_count = [0 for i in range(len(states_unique))] \n",
    "    for i in range(len(all_states_by_task[task])):\n",
    "        states_count[states_unique.index(all_states_by_task[task][i])] += all_times_by_task[task][i]\n",
    "    # normalize\n",
    "    states_count = [i/sum(states_count)*100 for i in states_count] \n",
    "    time_distrubution_by_task[task] = states_count\n",
    "    # median\n",
    "    # get std\n",
    "    # print\n",
    "    # get indices of the top 3 states\n",
    "    top3_indices = np.argsort(states_count)[-3:]\n",
    "    print(f' {states_unique[top3_indices[2]]} ({states_count[top3_indices[2]]:.2f}) newline  {states_unique[top3_indices[1]]} ({states_count[top3_indices[1]]:.2f}) newline  {states_unique[top3_indices[0]]} ({states_count[top3_indices[0]]:.2f})')\n",
    "    #for i in range(len(states_unique)):\n",
    "    #    print(f' {states_unique[i]}  {states_count[i]:.2f} ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By Expertise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_by_user_session_labeled[3].UserExperience[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(logs_by_user_session_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "all_states = []\n",
    "all_actions = []\n",
    "all_times = []\n",
    "for i in range(len(logs_by_user_session_labeled)):\n",
    "    states = logs_by_user_session_labeled[i].LabeledState.to_numpy()\n",
    "    actions = logs_by_user_session_labeled[i].StateName.to_numpy()\n",
    "    times = logs_by_user_session_labeled[i].TimeSpentInState.to_numpy()\n",
    "    # clean up states\n",
    "    for j in range(len(states)):\n",
    "        if states[j] == 'Edditing Last Suggestion (X)':\n",
    "            states[j] = 'Editing Last Suggestion (X)'\n",
    "        if states[j] == 'IDK':\n",
    "            states[j] = 'IDK (I)'\n",
    "        if states[j] == 'Looking up documentation' or states[j] == 'Looking up documentation (N)':\n",
    "            states[j] = 'Looking up Documentation (N)'\n",
    "        if states[j] == 'h':\n",
    "            states[j] = 'Thinking About New Code To Write (F)'\n",
    "        if states[j] == 'Thinking about new code to write (F)':\n",
    "            states[j] = 'Thinking About New Code To Write (F)'\n",
    "\n",
    "    # get indices where state is IDK\n",
    "    idk_indices = [i for i in range(len(states)) if states[i] == 'IDK (I)']\n",
    "    states = [states[i] for i in range(len(states)) if i not in idk_indices]\n",
    "    actions = [actions[i] for i in range(len(actions)) if i not in idk_indices]\n",
    "    times = [times[i] for i in range(len(times)) if i not in idk_indices]\n",
    "\n",
    "    all_states.append(states)\n",
    "    all_actions.append(actions)\n",
    "    all_times.append(times)\n",
    "\n",
    "all_states_by_expertise = {'copilot_exp': [], 'no_copilot_exp': [], 'exp_prog': [], 'no_exp_prog': []}\n",
    "all_actions_by_expertise= {'copilot_exp': [], 'no_copilot_exp': [], 'exp_prog': [], 'no_exp_prog': []}\n",
    "all_times_by_expertise = {'copilot_exp': [], 'no_copilot_exp': [], 'exp_prog': [], 'no_exp_prog': []}\n",
    "group_count = {'copilot_exp': 0, 'no_copilot_exp': 0, 'exp_prog': 0, 'no_exp_prog': 0}\n",
    "\n",
    "for i in range(len(all_states)):\n",
    "    user_charac= logs_by_user_session_labeled[i].UserExperience[0]\n",
    "    if user_charac['How often do you use Copilot outside of today’s session?'] != 'Never':\n",
    "        all_states_by_expertise['copilot_exp'].extend(all_states[i])\n",
    "        all_actions_by_expertise['copilot_exp'].extend(all_actions[i])\n",
    "        all_times_by_expertise['copilot_exp'].extend(all_times[i])\n",
    "        group_count['copilot_exp'] += 1\n",
    "    else:\n",
    "        all_states_by_expertise['no_copilot_exp'].extend(all_states[i])\n",
    "        all_actions_by_expertise['no_copilot_exp'].extend(all_actions[i])\n",
    "        all_times_by_expertise['no_copilot_exp'].extend(all_times[i])\n",
    "        group_count['no_copilot_exp'] += 1\n",
    "    if user_charac['Which best describes your programming experience?'] in [' 3 to 5 years professional programming experience', ' 0 to 2 years professional programming experience']:\n",
    "        all_states_by_expertise['no_exp_prog'].extend(all_states[i])\n",
    "        all_actions_by_expertise['no_exp_prog'].extend(all_actions[i])\n",
    "        all_times_by_expertise['no_exp_prog'].extend(all_times[i])\n",
    "        group_count['no_exp_prog'] += 1\n",
    "    else:\n",
    "        all_states_by_expertise['exp_prog'].extend(all_states[i])\n",
    "        all_actions_by_expertise['exp_prog'].extend(all_actions[i])\n",
    "        all_times_by_expertise['exp_prog'].extend(all_times[i])\n",
    "        group_count['exp_prog'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for group in all_states_by_expertise:\n",
    "    print(group)\n",
    "    \n",
    "    import collections\n",
    "    counter = collections.Counter(all_actions_by_expertise[group])\n",
    "    # normalize counter\n",
    "    counter_normalized = {k: v/sum(counter.values()) for k, v in counter.items()}\n",
    "    print(counter)\n",
    "    print(f' Accept Rate is {counter[\"Accepted\"]/ counter[\"Shown\"]}')\n",
    "    all_actions_binary = [] \n",
    "    # for each list in all_actions, keep only Accepted and Rejected and convert to binary\n",
    "    # get standard error of bernoulli\n",
    "    # create list of 0s of lenght counter[\"Shown\"]\n",
    "    all_actions_binary = [0]*counter[\"Shown\"]\n",
    "    # add 1s for Accepted\n",
    "    all_actions_binary[:counter[\"Accepted\"]] = [1]*counter[\"Accepted\"]\n",
    "    print(f' Mean is {np.mean(all_actions_binary)}')\n",
    "    group_size = group_count[group]\n",
    "    print(f' Standard Error is {np.std(all_actions_binary)/np.sqrt(group_size)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi square test to compare means\n",
    "# NOT USED\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "counter_exp = collections.Counter(all_actions_by_expertise['copilot_exp'])\n",
    "counter_notexp = collections.Counter(all_actions_by_expertise['no_copilot_exp'])\n",
    "table = [[counter_exp['Shown'] -counter_exp['Accepted'], counter_exp['Accepted']],[counter_notexp['Shown'] -counter_notexp['Accepted'], counter_notexp['Accepted']]]\n",
    "stat, p, dof, expected = chi2_contingency(table)\n",
    "print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret p-value\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same proportions of accepts (fail to reject H0)')\n",
    "else:\n",
    "    print('Different proportions of accepts (reject H0)')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi square test to compare means\n",
    "# NOT USED\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "counter_exp = collections.Counter(all_actions_by_expertise['exp_prog'])\n",
    "counter_notexp = collections.Counter(all_actions_by_expertise['no_exp_prog'])\n",
    "table = [[counter_exp['Shown'] -counter_exp['Accepted'], counter_exp['Accepted']],[counter_notexp['Shown'] -counter_notexp['Accepted'], counter_notexp['Accepted']]]\n",
    "stat, p, dof, expected = chi2_contingency(table)\n",
    "print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret p-value\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same proportions of accepts (fail to reject H0)')\n",
    "else:\n",
    "    print('Different proportions of accepts (reject H0)')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 6.3 Defer Thought\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states = []\n",
    "all_actions = []\n",
    "all_times = []\n",
    "all_suggestions = []\n",
    "all_states_continuous = []\n",
    "all_times_continuous = []\n",
    "all_actions_continuous = []\n",
    "for i in range(len(logs_by_user_session_labeled)):\n",
    "    states = logs_by_user_session_labeled[i].LabeledState.to_numpy()\n",
    "    actions = logs_by_user_session_labeled[i].StateName.to_numpy()\n",
    "    times = logs_by_user_session_labeled[i].TimeSpentInState.to_numpy()\n",
    "    suggestions = logs_by_user_session_labeled[i].CurrentSuggestion.to_numpy()\n",
    "    # clean up states\n",
    "    for j in range(len(states)):\n",
    "        if states[j] == 'IDK':\n",
    "            states[j] = 'IDK (I)'\n",
    "        if states[j] == 'Looking up documentation' or states[j] == 'Looking up documentation (N)':\n",
    "            states[j] = 'Looking up Documentation (N)'\n",
    "        if states[j] == 'h':\n",
    "            states[j] = 'Thinking About New Code To Write (F)'\n",
    "        if states[j] == 'Thinking about new code to write (F)':\n",
    "            states[j] = 'Thinking About New Code To Write (F)'\n",
    "\n",
    "    # get indices where state is IDK\n",
    "    idk_indices = [i for i in range(len(states)) if states[i] == 'IDK (I)']\n",
    "    states = [states[i] for i in range(len(states)) if i not in idk_indices]\n",
    "    actions = [actions[i] for i in range(len(actions)) if i not in idk_indices]\n",
    "    times = [times[i] for i in range(len(times)) if i not in idk_indices]\n",
    "\n",
    "    states_continuous = []\n",
    "    times_continuous = []\n",
    "    actions_continuous = []\n",
    "    # merge states with same name\n",
    "    last_state = \"\"\n",
    "    times_cumalitive = 0\n",
    "    for i in range(len(states)):\n",
    "        if states[i] != last_state:\n",
    "            states_continuous.append(states[i])\n",
    "            last_state = states[i]\n",
    "            times_continuous.append(times_cumalitive + times[i])\n",
    "            times_cumalitive = 0\n",
    "        else:\n",
    "            times_cumalitive += times[i]\n",
    "    all_states_continuous.extend(states_continuous)\n",
    "    all_times_continuous.extend(times_continuous)\n",
    "    all_states.append(states)\n",
    "    all_actions.append(actions)\n",
    "    all_times.append(times)\n",
    "    all_suggestions.append(suggestions)\n",
    "# merge all pandas dataframes of logs_by_user_session_labeled into a single dataframe\n",
    "all_users_df = pd.concat(logs_by_user_session_labeled)\n",
    "all_users_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_all = collections.Counter(all_states_continuous)\n",
    "print(counter_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get suggestions in all_users_df where LabeledState is Defered Thought\n",
    "defered_thought_suggestions = all_users_df[all_users_df['LabeledState'] == 'Deferring Thought For Later (D)'].CurrentSuggestion.to_numpy()\n",
    "thinking_suggestions = all_users_df[all_users_df['LabeledState'] == 'Thinking/Verifying Suggestion (A)'].CurrentSuggestion.to_numpy()\n",
    "# print random sample of suggestions from each \n",
    "#print('defered_thought_suggestions \\n \\n')\n",
    "#print(defered_thought_suggestions[np.random.randint(len(defered_thought_suggestions), size=10)])\n",
    "#print('thinking suggestions \\n \\n')\n",
    "#print(thinking_suggestions[np.random.randint(len(thinking_suggestions), size=10)])\n",
    "\n",
    "# compare number of characters and lines between the two groups\n",
    "defered_thought_suggestions_characters = []\n",
    "thinking_suggestions_characters = []\n",
    "defered_thought_suggestions_lines = []\n",
    "thinking_suggestions_lines = []\n",
    "for i in range(len(defered_thought_suggestions)):\n",
    "    defered_thought_suggestions_characters.append(len(defered_thought_suggestions[i]))\n",
    "    defered_thought_suggestions_lines.append(len(defered_thought_suggestions[i].split('\\\\n')))\n",
    "\n",
    "for i in range(len(thinking_suggestions)):\n",
    "    thinking_suggestions_characters.append(len(thinking_suggestions[i]))\n",
    "    thinking_suggestions_lines.append(len(thinking_suggestions[i].split('\\\\n')))\n",
    "\n",
    "# print average and median number of characters and lines for each group\n",
    "print(f'n = {len(defered_thought_suggestions)} Avg characters for defered thought suggestions: {np.mean(defered_thought_suggestions_characters):.2f} median characters: {np.median(defered_thought_suggestions_characters):.2f} std characters: {np.std(defered_thought_suggestions_characters):.2f}')\n",
    "print(f'Avg lines for defered thought suggestions: {np.mean(defered_thought_suggestions_lines):.2f} median lines: {np.median(defered_thought_suggestions_lines):.2f} std lines: {np.std(defered_thought_suggestions_lines):.2f}')\n",
    "print(f'n = {len(thinking_suggestions_characters)} Avg characters for thinking suggestions: {np.mean(thinking_suggestions_characters):.2f} median characters: {np.median(thinking_suggestions_characters):.2f} std characters: {np.std(thinking_suggestions_characters):.2f}')\n",
    "print(f'Avg lines for thinking suggestions: {np.mean(thinking_suggestions_lines):.2f} median lines: {np.median(thinking_suggestions_lines):.2f} std lines: {np.std(thinking_suggestions_lines):.2f}')\n",
    "# two sample t test, one for characters and one for lines\n",
    "from scipy.stats import ttest_ind\n",
    "print(f'ttest_ind(thinking_suggestions_characters, defered_thought_suggestions_characters) = {ttest_ind(thinking_suggestions_characters, defered_thought_suggestions_characters)}')\n",
    "print(f'ttest_ind(thinking_suggestions_lines, defered_thought_suggestions_lines) = {ttest_ind(thinking_suggestions_lines, defered_thought_suggestions_lines)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_states_defer = {}\n",
    "prev_states_thinking = {}\n",
    "for j in range(1, len(all_states)):\n",
    "    for i in range(len(all_states[j])):\n",
    "        if all_states[j][i] == 'Deferring Thought For Later (D)':\n",
    "            if all_states[j][i-1] not in prev_states_defer:\n",
    "                prev_states_defer[all_states[j][i-1]] = 1\n",
    "            else:\n",
    "                prev_states_defer[all_states[j][i-1]] += 1\n",
    "        if all_states[j][i] == 'Thinking/Verifying Suggestion (A)':\n",
    "            if all_states[j][i-1] not in prev_states_thinking:\n",
    "                prev_states_thinking[all_states[j][i-1]] = 1\n",
    "            else:\n",
    "                prev_states_thinking[all_states[j][i-1]] += 1\n",
    "\n",
    "# instead of counts make it a probability\n",
    "sum_defer = sum(prev_states_defer.values())\n",
    "for key in prev_states_defer:\n",
    "    prev_states_defer[key] = prev_states_defer[key]/sum_defer\n",
    "sum_thinking = sum(prev_states_thinking.values())\n",
    "for key in prev_states_thinking:\n",
    "    prev_states_thinking[key] = prev_states_thinking[key]/sum_thinking\n",
    "    \n",
    "# print\n",
    "print(f'prev_states_defer = {prev_states_defer}')\n",
    "print(f'prev_states_thinking = {prev_states_thinking}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_edits = {'Deferring Thought For Later (D)':0, 'Thinking/Verifying Suggestion (A)':0, 'Waiting For Suggestion (G)':0, 'Thinking About New Code To Write (F)':0}\n",
    "counts_states = {'Deferring Thought For Later (D)':0, 'Thinking/Verifying Suggestion (A)':0, 'Waiting For Suggestion (G)':0, 'Thinking About New Code To Write (F)':0}\n",
    "\n",
    "for j in range(len(all_states)):\n",
    "    for i in range(len(all_states[j])-1):\n",
    "        if all_actions[j][i] in ['Accepted']:\n",
    "            if all_states[j][i] == 'Thinking/Verifying Suggestion (A)':\n",
    "                counts_states['Thinking/Verifying Suggestion (A)'] += 1\n",
    "                if all_states[j][i+1] == 'Editing Last Suggestion (X)':\n",
    "                    counts_edits['Thinking/Verifying Suggestion (A)'] += 1\n",
    "            if all_states[j][i] == 'Deferring Thought For Later (D)':\n",
    "                counts_states['Deferring Thought For Later (D)'] += 1\n",
    "                if all_states[j][i+1] == 'Thinking/Verifying Suggestion (A)':\n",
    "                    counts_edits['Deferring Thought For Later (D)'] += 1\n",
    "            if all_states[j][i] == 'Waiting For Suggestion (G)':\n",
    "                counts_states['Waiting For Suggestion (G)'] += 1\n",
    "                if all_states[j][i+1] == 'Thinking/Verifying Suggestion (A)':\n",
    "                    counts_edits['Waiting For Suggestion (G)'] += 1\n",
    "            if all_states[j][i] == 'Thinking About New Code To Write (F)':\n",
    "                counts_states['Thinking About New Code To Write (F)'] += 1\n",
    "                if all_states[j][i+1] == 'Thinking/Verifying Suggestion (A)':\n",
    "                    counts_edits['Thinking About New Code To Write (F)'] += 1\n",
    "# print probability of edit\n",
    "print(counts_edits)\n",
    "print(counts_states)\n",
    "print(f'Probability of edit Thinking/Verifying Suggestion (A):  {counts_edits[\"Thinking/Verifying Suggestion (A)\"]/counts_states[\"Thinking/Verifying Suggestion (A)\"]}')\n",
    "print(f'Probability of edit Deferring Thought For Late: {counts_edits[\"Deferring Thought For Later (D)\"]/counts_states[\"Deferring Thought For Later (D)\"]}')\n",
    "print(f'Probability of edit Thinking About New Code To Write: {counts_edits[\"Thinking About New Code To Write (F)\"]/counts_states[\"Thinking About New Code To Write (F)\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "thinking_accepts = [0] * counts_states['Thinking/Verifying Suggestion (A)']\n",
    "thinking_accepts[0:counts_edits['Thinking/Verifying Suggestion (A)']] = [1] * counts_edits['Thinking/Verifying Suggestion (A)']\n",
    "writing_accepts = [0] * counts_states['Deferring Thought For Later (D)']\n",
    "writing_accepts[0:counts_edits['Deferring Thought For Later (D)']] = [1] * counts_edits['Deferring Thought For Later (D)']\n",
    "# shuffle both arrays\n",
    "np.random.shuffle(thinking_accepts)\n",
    "np.random.shuffle(writing_accepts)\n",
    "\n",
    "\n",
    "# chi square test to compare means\n",
    "from scipy.stats import chi2_contingency\n",
    "table = [[counts_edits['Thinking/Verifying Suggestion (A)'], counts_states['Thinking/Verifying Suggestion (A)'] - counts_edits['Thinking/Verifying Suggestion (A)']], [counts_edits['Deferring Thought For Later (D)'], counts_states['Deferring Thought For Later (D)'] - counts_edits['Deferring Thought For Later (D)']]]\n",
    "\n",
    "stat, p, dof, expected = chi2_contingency(table)\n",
    "print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret p-value\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same proportions of accepts (fail to reject H0)')\n",
    "else:\n",
    "    print('Different proportions of accepts (reject H0)')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accept rate before shown\n",
    "states_accept = {}\n",
    "states_count = {}\n",
    "\n",
    "for j in range(len(all_states)):\n",
    "    for i in range(1, len(all_states[j])):\n",
    "        if all_actions[j][i] in ['Accepted', 'Rejected']:\n",
    "            state_now = all_states[j][i]\n",
    "            state_before = all_states[j][i-1]\n",
    "            if state_before not in states_count:\n",
    "                states_accept[state_before] = 0\n",
    "                states_count[state_before] = 1\n",
    "            else:  \n",
    "                states_count[state_before] += 1\n",
    "            \n",
    "            if all_actions[j][i] == 'Accepted':\n",
    "                states_accept[state_before] += 1\n",
    "\n",
    "\n",
    "print(f'Probability of accept for each state:')\n",
    "for state in states_count:\n",
    "    print(f'{state}: {states_accept[state]/states_count[state]} {np.std([1]*states_accept[state] + [0]*(states_count[state] - states_accept[state]))/np.sqrt(states_count[state])}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accept rate while shown\n",
    "states_accept = {}\n",
    "states_count = {}\n",
    "\n",
    "for j in range(len(all_states)):\n",
    "    for i in range(1, len(all_states[j])):\n",
    "        if all_actions[j][i] in ['Accepted', 'Rejected']:\n",
    "            state_now = all_states[j][i]\n",
    "            if state_now not in states_count:\n",
    "                states_count[state_now] = 1\n",
    "                states_accept[state_now] = 0\n",
    "\n",
    "            else:\n",
    "                states_count[state_now] += 1\n",
    "            \n",
    "            if all_actions[j][i] == 'Accepted':\n",
    "                states_accept[state_now] += 1\n",
    "\n",
    "print(f'Probability of accept for each state:')\n",
    "# and standard error\n",
    "for state in states_count:\n",
    "    print(f'{state}: {states_accept[state]/states_count[state]} {np.std([1]*states_accept[state] + [0]*(states_count[state] - states_accept[state]))/np.sqrt(states_count[state])}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "thinking_accepts = [0] * states_count['Thinking/Verifying Suggestion (A)']\n",
    "thinking_accepts[0:states_accept['Thinking/Verifying Suggestion (A)']] = [1] * states_accept['Thinking/Verifying Suggestion (A)']\n",
    "writing_accepts = [0] * states_count['Thinking About New Code To Write (F)']\n",
    "writing_accepts[0:states_accept['Thinking About New Code To Write (F)']] = [1] * states_accept['Thinking About New Code To Write (F)']\n",
    "# shuffle both arrays\n",
    "np.random.shuffle(thinking_accepts)\n",
    "np.random.shuffle(writing_accepts)\n",
    "\n",
    "\n",
    "# chi square test to compare means\n",
    "from scipy.stats import chi2_contingency\n",
    "table = [[states_accept['Thinking/Verifying Suggestion (A)'], states_count['Thinking/Verifying Suggestion (A)'] - states_accept['Thinking/Verifying Suggestion (A)']], [states_accept['Thinking About New Code To Write (F)'], states_count['Thinking About New Code To Write (F)'] - states_accept['Thinking About New Code To Write (F)']]]\n",
    "stat, p, dof, expected = chi2_contingency(table)\n",
    "print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret p-value\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same proportions of accepts (fail to reject H0)')\n",
    "else:\n",
    "    print('Different proportions of accepts (reject H0)')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cups time to verify (section 6.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states = []\n",
    "all_actions = []\n",
    "all_times = []\n",
    "all_suggestions = []\n",
    "all_states_continuous = []\n",
    "all_times_continuous = []\n",
    "all_actions_continuous = []\n",
    "for i in range(len(logs_by_user_session_labeled)):\n",
    "    states = logs_by_user_session_labeled[i].LabeledState.to_numpy()\n",
    "    actions = logs_by_user_session_labeled[i].StateName.to_numpy()\n",
    "    times = logs_by_user_session_labeled[i].TimeSpentInState.to_numpy()\n",
    "    suggestions = logs_by_user_session_labeled[i].CurrentSuggestion.to_numpy()\n",
    "    # clean up states\n",
    "    for j in range(len(states)):\n",
    "        if states[j] == 'IDK':\n",
    "            states[j] = 'IDK (I)'\n",
    "        if states[j] == 'Looking up documentation' or states[j] == 'Looking up documentation (N)':\n",
    "            states[j] = 'Looking up Documentation (N)'\n",
    "        if states[j] == 'h':\n",
    "            states[j] = 'Thinking About New Code To Write (F)'\n",
    "        if states[j] == 'Thinking about new code to write (F)':\n",
    "            states[j] = 'Thinking About New Code To Write (F)'\n",
    "\n",
    "    # get indices where state is IDK\n",
    "    idk_indices = [i for i in range(len(states)) if states[i] == 'IDK (I)']\n",
    "    states = [states[i] for i in range(len(states)) if i not in idk_indices]\n",
    "    actions = [actions[i] for i in range(len(actions)) if i not in idk_indices]\n",
    "    times = [times[i] for i in range(len(times)) if i not in idk_indices]\n",
    "\n",
    "    states_continuous = []\n",
    "    times_continuous = []\n",
    "    actions_continuous = []\n",
    "    # merge states with same name\n",
    "    last_state = \"\"\n",
    "    times_cumalitive = 0\n",
    "    for i in range(len(states)):\n",
    "        if states[i] != last_state:\n",
    "            states_continuous.append(states[i])\n",
    "            last_state = states[i]\n",
    "            times_continuous.append(times_cumalitive + times[i])\n",
    "            times_cumalitive = 0\n",
    "        else:\n",
    "            times_cumalitive += times[i]\n",
    "    all_states_continuous.extend(states_continuous)\n",
    "    all_times_continuous.extend(times_continuous)\n",
    "    all_states.append(states)\n",
    "    all_actions.append(actions)\n",
    "    all_times.append(times)\n",
    "    all_suggestions.append(suggestions)\n",
    "# merge all pandas dataframes of logs_by_user_session_labeled into a single dataframe\n",
    "all_users_df = pd.concat(logs_by_user_session_labeled)\n",
    "all_users_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for defer thought, check time after\n",
    "defer_thought_original = []\n",
    "defer_thought_new = []\n",
    "post_thinking_time = []\n",
    "for j in range(len(all_states)):\n",
    "    for i in range(len(all_states[j])-1):\n",
    "        if  all_states[j][i] == 'Deferring Thought For Later (D)' and all_actions[j][i] == 'Accepted':\n",
    "            defer_thought_original.append(all_times[j][i])\n",
    "            if all_states[j][i+1] == 'Thinking/Verifying Suggestion (A)':\n",
    "                defer_thought_new.append(all_times[j][i+1]+ all_times[j][i])\n",
    "                post_thinking_time.append(all_times[j][i+1])\n",
    "            else:\n",
    "                defer_thought_new.append(all_times[j][i])\n",
    "# mean of original and new\n",
    "print(f'how often verify after defer = {len(post_thinking_time)/len(defer_thought_new)}')\n",
    "print(f'Defer Thought should add the thinking veriyfing suggestion time after the action n = {len(defer_thought_original)}')\n",
    "print(f' (means) before adjusting: {np.mean(defer_thought_original):.2f} +- {np.std(defer_thought_original):.2f} after adjusting: {np.mean(defer_thought_new):.2f} +- {np.std(defer_thought_new):.2f}')\n",
    "print(f' (median) before adjusting: {np.median(defer_thought_original):.2f} +- {np.std(defer_thought_original):.2f} after adjusting: {np.median(defer_thought_new):.2f} +- {np.std(defer_thought_new):.2f}')\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_rel.html\n",
    "print(f' post thinking time (means) {np.mean(post_thinking_time):.2f} +- {np.std(post_thinking_time):.2f} occurs {len(post_thinking_time)/len(defer_thought_new)}')\n",
    "# paired t-test\n",
    "import scipy\n",
    "def paired_ttest(a, b):\n",
    "    return scipy.stats.ttest_rel(a, b)\n",
    "print(paired_ttest(defer_thought_original, defer_thought_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for thinking , check time after\n",
    "thinking_original = []\n",
    "thinking_new = []\n",
    "post_thinking_time = []\n",
    "\n",
    "for j in range(len(all_states)):\n",
    "    for i in range(len(all_states[j])-1):\n",
    "        if  all_states[j][i] == 'Thinking/Verifying Suggestion (A)' and all_actions[j][i] == 'Accepted':\n",
    "            thinking_original.append(all_times[j][i])\n",
    "            new_time = all_times[j][i]\n",
    "            if all_states[j][i+1] == 'Thinking/Verifying Suggestion (A)':\n",
    "                new_time += all_times[j][i+1]\n",
    "                post_thinking_time.append(all_times[j][i+1])\n",
    "\n",
    "            #if all_states[j][i-1] == 'Waiting For Suggestion (G)':\n",
    "            #    new_time += all_times[j][i-1]\n",
    "            thinking_new.append(new_time)\n",
    "# mean of original and new\n",
    "\n",
    "# print\n",
    "print(f' post thinking time (means) {np.mean(post_thinking_time):.2f} +- {np.std(post_thinking_time):.2f} occurs {len(post_thinking_time)/len(thinking_new)}')\n",
    "\n",
    "print(f'Thinking should add  and time spent thinking after   n={len(thinking_new)} ')\n",
    "print(f'(means) before adjusting: {np.mean(thinking_original):.2f} +- {np.std(thinking_original):.2f} after adjusting: {np.mean(thinking_new):.2f} +- {np.std(thinking_new):.2f}')\n",
    "print(f' (median) before adjusting: {np.median(thinking_original):.2f} +- {np.std(thinking_original):.2f} after adjusting: {np.median(thinking_new):.2f} +- {np.std(thinking_new):.2f}')\n",
    "print(paired_ttest(thinking_original, thinking_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thinking_original = []\n",
    "thinking_new = []\n",
    "waiting_time = []\n",
    "for j in range(len(all_states)):\n",
    "    for i in range(len(all_states[j])-1):\n",
    "        if all_actions[j][i] in ['Accepted', 'Rejected'] and all_states[j][i] in ['Thinking/Verifying Suggestion (A)',\n",
    "                'Waiting For Suggestion (G)', 'Deferring Thought For Later (D)', 'Thinking About New Code To Write (F)']:\n",
    "            thinking_original.append(all_times[j][i])\n",
    "            new_time = all_times[j][i]\n",
    "            if all_states[j][i-1] == 'Waiting For Suggestion (G)':\n",
    "                waiting_time.append(all_times[j][i-1])\n",
    "                new_time += all_times[j][i-1]\n",
    "            thinking_new.append(new_time)\n",
    "# mean of original and new\n",
    "\n",
    "# print\n",
    "print(f'Thinking should add  the time spent waiting before  n={len(thinking_new)} ')\n",
    "print(f'(means) before adjusting: {np.mean(thinking_original):.2f} +- {np.std(thinking_original):.2f} after adjusting: {np.mean(thinking_new):.2f} +- {np.std(thinking_new):.2f}')\n",
    "print(f' (median) before adjusting: {np.median(thinking_original):.2f} +- {np.std(thinking_original):.2f} after adjusting: {np.median(thinking_new):.2f} +- {np.std(thinking_new):.2f}')\n",
    "print(paired_ttest(thinking_original, thinking_new))\n",
    "print(f' waiting time {np.mean(waiting_time):.2f} +- {np.std(waiting_time):.2f} and probability {len(waiting_time)/len(thinking_new)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Crafting Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states = []\n",
    "all_actions = []\n",
    "all_times = []\n",
    "all_suggestions = []\n",
    "all_states_continuous = []\n",
    "all_times_continuous = []\n",
    "all_actions_continuous = []\n",
    "for i in range(len(logs_by_user_session_labeled)):\n",
    "    states = logs_by_user_session_labeled[i].LabeledState.to_numpy()\n",
    "    actions = logs_by_user_session_labeled[i].StateName.to_numpy()\n",
    "    times = logs_by_user_session_labeled[i].TimeSpentInState.to_numpy()\n",
    "    suggestions = logs_by_user_session_labeled[i].CurrentSuggestion.to_numpy()\n",
    "    # clean up states\n",
    "    for j in range(len(states)):\n",
    "        if states[j] == 'IDK':\n",
    "            states[j] = 'IDK (I)'\n",
    "        if states[j] == 'Looking up documentation' or states[j] == 'Looking up documentation (N)':\n",
    "            states[j] = 'Looking up Documentation (N)'\n",
    "        if states[j] == 'h':\n",
    "            states[j] = 'Thinking About New Code To Write (F)'\n",
    "        if states[j] == 'Thinking about new code to write (F)':\n",
    "            states[j] = 'Thinking About New Code To Write (F)'\n",
    "\n",
    "    # get indices where state is IDK\n",
    "    idk_indices = [i for i in range(len(states)) if states[i] == 'IDK (I)']\n",
    "    states = [states[i] for i in range(len(states)) if i not in idk_indices]\n",
    "    actions = [actions[i] for i in range(len(actions)) if i not in idk_indices]\n",
    "    times = [times[i] for i in range(len(times)) if i not in idk_indices]\n",
    "\n",
    "    states_continuous = []\n",
    "    times_continuous = []\n",
    "    actions_continuous = []\n",
    "    # merge states with same name\n",
    "    last_state = \"\"\n",
    "    times_cumalitive = 0\n",
    "    for i in range(len(states)):\n",
    "        if states[i] != last_state:\n",
    "            states_continuous.append(states[i])\n",
    "            last_state = states[i]\n",
    "            times_continuous.append(times_cumalitive + times[i])\n",
    "            times_cumalitive = 0\n",
    "        else:\n",
    "            times_cumalitive += times[i]\n",
    "    all_states_continuous.extend(states_continuous)\n",
    "    all_times_continuous.extend(times_continuous)\n",
    "    all_states.append(states)\n",
    "    all_actions.append(actions)\n",
    "    all_times.append(times)\n",
    "    all_suggestions.append(suggestions)\n",
    "# merge all pandas dataframes of logs_by_user_session_labeled into a single dataframe\n",
    "all_users_df = pd.concat(logs_by_user_session_labeled)\n",
    "all_users_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability of accept while prompt crafting\n",
    "prompt_crafting_count = 0\n",
    "accepted_when_prompt_crafting = 0\n",
    "for j in range(len(all_states)):\n",
    "    for i in range(1, len(all_states[j])-1):\n",
    "        if all_actions[j][i] in ['Accepted', 'Rejected']:\n",
    "            if all_states[j][i] == 'Prompt Crafting (V)':\n",
    "                prompt_crafting_count += 1\n",
    "                if all_actions[j][i] == 'Accepted':# and all_states[j][i+1] == 'Prompt Crafting (V)':\n",
    "                        accepted_when_prompt_crafting += 1\n",
    "\n",
    "print(f'n = {prompt_crafting_count} Probability of accept while prompt crafting: {accepted_when_prompt_crafting/prompt_crafting_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start prompt crafting - inside should be anything but \n",
    "prompt_crafting_count = 0\n",
    "accepted_when_prompt_crafting = 0\n",
    "for j in range(len(all_states)):\n",
    "    i = 0\n",
    "    while i < len(all_states[j]):\n",
    "        if all_states[j][i] == 'Prompt Crafting (V)':\n",
    "            # get state where prompt crafting ends\n",
    "            prompt_crafting_count += 1\n",
    "            last_episode_state = i\n",
    "            first_pos_accept = -1\n",
    "            for k in range(i, len(all_states[j]) ):\n",
    "                if all_actions[j][k] == 'Accepted':\n",
    "                    first_pos_accept = k\n",
    "                    break\n",
    "\n",
    "            for k in range(i, len(all_states[j])):\n",
    "                if all_states[j][k] in ['Writing New Functionality (Z)', 'Editing Written Code(C)','Thinking About New Code To Write (F)','Debugging/Testing Code (H)', 'Looking up Documentation (N)', 'Writing Documentation (B)']:\n",
    "                    # this means prompt crafting ended, let's check if there was an accept just before prompt crafting ended\n",
    "                    last_episode_state = k\n",
    "                    break\n",
    "\n",
    "            last_prompt_state = i\n",
    "            while all_states[j][last_prompt_state] == 'Prompt Crafting (V)' and last_prompt_state < len(all_states[j]) -1:\n",
    "                last_prompt_state += 1\n",
    "            last_prompt_state -= 1\n",
    "\n",
    "            if first_pos_accept < max(last_prompt_state,last_episode_state):\n",
    "                accepted_when_prompt_crafting += 1\n",
    "                \n",
    "            i = max(last_episode_state,last_prompt_state) +1\n",
    "            # print the trajectory\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "print(f'n = {prompt_crafting_count} Probability of accept after prompt crafting: {accepted_when_prompt_crafting/prompt_crafting_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transitions between states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from entropy_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states = []\n",
    "all_actions = []\n",
    "all_times = []\n",
    "all_states_continuous = []\n",
    "all_states_list = []\n",
    "all_times_list = []\n",
    "\n",
    "all_times_continuous = []\n",
    "for i in range(len(logs_by_user_session_labeled)):\n",
    "    states = logs_by_user_session_labeled[i].LabeledState.to_numpy()\n",
    "    actions = logs_by_user_session_labeled[i].StateName.to_numpy()\n",
    "    times = logs_by_user_session_labeled[i].TimeSpentInState.to_numpy()\n",
    "    # clean up states\n",
    "    for j in range(len(states)):\n",
    "        if states[j] == 'Edditing Last Suggestion (X)':\n",
    "            states[j] = 'Editing Last Suggestion (X)'\n",
    "        if states[j] == 'IDK':\n",
    "            states[j] = 'IDK (I)'\n",
    "        if states[j] == 'Looking up documentation' or states[j] == 'Looking up documentation (N)':\n",
    "            states[j] = 'Looking up Documentation (N)'\n",
    "        if states[j] == 'h':\n",
    "            states[j] = 'Thinking About New Code To Write (F)'\n",
    "        if states[j] == 'Thinking about new code to write (F)':\n",
    "            states[j] = 'Thinking About New Code To Write (F)'\n",
    "\n",
    "    # get indices where state is IDK\n",
    "    idk_indices = [i for i in range(len(states)) if states[i] == 'IDK (I)']\n",
    "    states = [states[i] for i in range(len(states)) if i not in idk_indices]\n",
    "    actions = [actions[i] for i in range(len(actions)) if i not in idk_indices]\n",
    "    times = [times[i] for i in range(len(times)) if i not in idk_indices]\n",
    "\n",
    "    states_continuous = []\n",
    "    times_continuous = []\n",
    "    # merge states with same name\n",
    "    last_state = states[0]\n",
    "    times_cumalitive = 0\n",
    "    for i in range(len(states)):\n",
    "        if states[i] != last_state:\n",
    "            states_continuous.append(last_state)\n",
    "            last_state = states[i]\n",
    "            times_continuous.append(times_cumalitive)\n",
    "            times_cumalitive = times[i]\n",
    "        else:\n",
    "            times_cumalitive += times[i]\n",
    "    states_continuous.append(last_state)\n",
    "    times_continuous.append(times_cumalitive)\n",
    "    \n",
    "    all_states_list.extend(states)\n",
    "    all_times_list.extend(times)\n",
    "    all_states_continuous.extend(states_continuous)\n",
    "    all_times_continuous.extend(times_continuous)\n",
    "    all_states.append(states)\n",
    "    all_actions.append(actions)\n",
    "    all_times.append(times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = pd.crosstab(\n",
    "    pd.Series(all_states_continuous[:-1], name='Today'),\n",
    "    pd.Series(all_states_continuous[1:], name='Tomorrow'),\n",
    "    normalize=0\n",
    ")\n",
    "\n",
    "\n",
    "graph = TransGraph(T)\n",
    "nodes_original = list(graph.dataframe.index)\n",
    "transition_matrix = np.array(graph.dataframe)\n",
    "nodes = list(graph.dataframe.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find most probable transition from each state\n",
    "# find most probable transition from each state\n",
    "\n",
    "for i in range(len(transition_matrix)):\n",
    "    # find max value in ro\n",
    "    max_val = max(transition_matrix[i])\n",
    "    # find index of max value in row\n",
    "    max_val_index = transition_matrix[i].tolist().index(max_val)\n",
    "    # add to dict\n",
    "    print(f' {nodes[i]} --- {transition_matrix[i][max_val_index]:.2f} ---> {nodes[max_val_index]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = stationary_distribution(transition_matrix)\n",
    "# get entropy rate of the MC\n",
    "entropy_rate = np.dot(mu.transpose(), local_entropy(transition_matrix))\n",
    "print(entropy_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "uniform_transition_matrix = np.ones((len(transition_matrix), len(transition_matrix)))/len(transition_matrix)\n",
    "\n",
    "mu = stationary_distribution(uniform_transition_matrix)\n",
    "# uniform transition matrix\n",
    "# get entropy rate of the MC\n",
    "entropy_rate = np.dot(mu.transpose(), local_entropy(uniform_transition_matrix))\n",
    "print(entropy_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# find most probable transition from each state\n",
    "nodes_original = list(graph.dataframe.index)\n",
    "\n",
    "for i in range(len(transition_matrix)):\n",
    "    # find top 2 values in row\n",
    "    top_2_values = sorted(transition_matrix[i], reverse=True)[:2]\n",
    "    # find indices of top 2 values in row\n",
    "    top_2_values_indices = [transition_matrix[i].tolist().index(x) for x in top_2_values]\n",
    "\n",
    "    # add to dict\n",
    "    print(f' {nodes_original[i]} --- {transition_matrix[i][top_2_values_indices[1]]:.2f} ---> {nodes_original[top_2_values_indices[1]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find most probable sequences\n",
    "from scipy.stats import itemfreq\n",
    "N = 3\n",
    "def list_to_string(lst):\n",
    "    return ' -> '.join(lst)\n",
    "grams = [list_to_string(all_states_continuous[i:i+N]) for i in range(len(all_states_continuous)-N)]\n",
    "# counter from grams\n",
    "from collections import Counter\n",
    "counter_grams = Counter(grams)\n",
    "# get most common grams\n",
    "most_common_grams = counter_grams.most_common(10)\n",
    "# print each on new line\n",
    "for i in range(len(most_common_grams)):\n",
    "    print(most_common_grams[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states_augmented = [] \n",
    "for i in range(len(logs_by_user_session_labeled)):\n",
    "    states = logs_by_user_session_labeled[i].LabeledState.to_numpy()\n",
    "    actions = logs_by_user_session_labeled[i].StateName.to_numpy()\n",
    "    times = logs_by_user_session_labeled[i].TimeSpentInState.to_numpy()\n",
    "    # clean up states\n",
    "    for j in range(len(states)):\n",
    "        if states[j] == 'IDK':\n",
    "            states[j] = 'IDK (I)'\n",
    "        if states[j] == 'Looking up documentation' or states[j] == 'Looking up documentation (N)':\n",
    "            states[j] = 'Looking up Documentation (N)'\n",
    "        if states[j] == 'h':\n",
    "            states[j] = 'Thinking About New Code To Write (F)'\n",
    "        if states[j] == 'Thinking about new code to write (F)':\n",
    "            states[j] = 'Thinking About New Code To Write (F)'\n",
    "\n",
    "    # get indices where state is IDK\n",
    "    idk_indices = [i for i in range(len(states)) if states[i] == 'IDK (I)']\n",
    "    states = [states[i] for i in range(len(states)) if i not in idk_indices]\n",
    "    actions = [actions[i] for i in range(len(actions)) if i not in idk_indices]\n",
    "    times = [times[i] for i in range(len(times)) if i not in idk_indices]\n",
    "\n",
    "    states_continuous = []\n",
    "    times_continuous = []\n",
    "    # merge states with same name\n",
    "    last_state = states[0]\n",
    "    times_cumalitive = 0\n",
    "    for i in range(len(states)):\n",
    "        all_states_augmented.append(states[i])\n",
    "        if actions[i] != 'Replay':\n",
    "            all_states_augmented.append(actions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find most probable sequences\n",
    "from scipy.stats import itemfreq\n",
    "N = 6\n",
    "def list_to_string(lst):\n",
    "    return ' -> '.join(lst)\n",
    "grams = [list_to_string(all_states_augmented[i:i+N]) for i in range(len(all_states_augmented)-N)]\n",
    "# counter from grams\n",
    "from collections import Counter\n",
    "counter_grams = Counter(grams)\n",
    "# get most common grams\n",
    "most_common_grams = counter_grams.most_common(50)\n",
    "# print each on new line\n",
    "for i in range(len(most_common_grams)):\n",
    "    print(most_common_grams[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find most probable sequences\n",
    "from scipy.stats import itemfreq\n",
    "N = 5\n",
    "def list_to_string(lst):\n",
    "    return ' -> '.join(lst)\n",
    "grams = [list_to_string(all_states_augmented[i:i+N]) for i in range(len(all_states_augmented)-N)]\n",
    "# counter from grams\n",
    "from collections import Counter\n",
    "counter_grams = Counter(grams)\n",
    "# get most common grams\n",
    "most_common_grams = counter_grams.most_common(10)\n",
    "# print each on new line\n",
    "for i in range(len(most_common_grams)):\n",
    "    print(most_common_grams[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p value correction\n",
    "p_values = [0.56,0,0,8*10**-6,4*10**-5]\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "multipletests(p_values, alpha=0.05, method='fdr_bh', is_sorted=False, returnsorted=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('hussein': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e710af216e809473b1f2bcdee939ed3d8fc69fba0a18fe13b179176696cffea0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
